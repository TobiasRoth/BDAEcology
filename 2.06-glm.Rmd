
# Generalized linear models {#glm}


## Introduction

Up to now, we have dealt with models that assume normally distributed residuals. Sometimes the nature of the outcome
variable makes it impossible to fulfill this assumption as might occur with binary variables (e.g., alive/dead, a specific behavior occurred/did not occur), proportions (which are confined to be between 0 and 1), or counts that cannot have negative values. For such cases, models for distributions other than the normal distribution are needed; such models are called generalized linear models (GLM). They consist of three elements:  
1. the linear predictor $\boldsymbol\beta \bf X$  
2. the link function $f()$  
3. the data distribution  

The linear predictor is exactly the same as in normal linear models. It is a linear function that defines the relationship between the dependent and the explanatory variables. The link function transforms the expected values of the outcome variable into the range of the linear predictor, which ranges from $-\infty$ to $+\infty$. Or, perhaps more intuitively, the inverse link function transforms the values of the linear predictor into the range of the outcome variable. Then, a
specific data distribution, for example, binomial or Poisson, is used to describe how the observations scatter around the expected values. A general model formula for a generalized linear model is:
$$\bf y \sim ExpDist(\bf\hat y, \boldsymbol\theta)$$
$$f(\bf\hat y) = \boldsymbol \beta \bf X$$
where *ExpDist* is a distribution of the exponential family and $f()$ is the link function. The vector $\bf y$ contains the observed values of the outcome variable, $\bf \beta$ contains the model parameters in the linear predictor (also called the model coefficients), and $\bf X$ is the model matrix containing the values of the predictor variables. $\boldsymbol \theta$ is an optional vector of additional parameters needed to define the data distribution (e.g., the number of trials in the binomial distribution or the variance in the normal distribution).
The normal linear model is a specific case of a generalized linear model, namely when *ExpDist* equals the normal distribution and $f()$ is the identity function ($f(x) = x$). Statistical distributions of the exponential family are normal, Bernoulli, binomial, Poisson, inverse-normal, gamma, negative binomial, among others. The normal, Bernoulli, binomial, Poisson or negative binomial distributions are by far the most often used distributions. Most, but not all, data we gather in the life sciences can be analyzed assuming one of these few distributions.


## Bernoulli model

If the outcome variable can only take one of two values (e.g., a species is present or absent, or the individual survived or died; often coded as 1 or 0) we use a Bernoulli model, also called logistic regression. The [Bernoulli distribution](bernoulli-dist) only allows for the values zero and ones and it has only one parameter $p$, which defines the probability that the value is 1. 

The variance of the Bernoulli distribution is defined by p and no separate variance parameter exists. However, because the data can only take the values 0 and 1, there is no possibility that the data can show a higher variance than the one assumed by the Bernoulli distribution. Therefore, we do not have to worry about overdispersion when the
outcome variable is binary.

A Bernoulli model is fitted in R using the function `glm` with the family argument set to `binomial`. That is because the Bernoulli distribution is equal to the binomial distribution with only one trial (size parameter = 1).

As an example, we use presence-absence data of little owls *Athene noctua* in nest boxes during the breeding season. The original data are published in @Gottschalk.2011; here we use only parts of these data. The variable `PA` contains the presence of a little owl: 1 indicates a nestbox used by little owls, whereas 0 stands for an empty nestbox. The variable `elevation` has the elevation in meters above sea level. We are interested in how the presence of the little owl is associated with elevation within the study area, that is, how the probability of presence changes with elevation. Our primary interest, therefore, is the slope $\beta_1$ of the regression line.

$$ y_i \sim Bernoulli(p_i) $$
$$ logit(p_i) = \beta_0 + \beta_1 elevation$$
where $logit(p_i) = log(p_i/(1-p_i))$.
To fit this model, we use the `glm` function with `family=binomial`. Note, if we forget the `family` argument, we fit a normal linear model, and there is no warning by R!

```{r}
data(anoctua) # Athene noctua data in the blmeco package
mod <- glm(PA~elevation, data=anoctua, family=binomial)
mod
```

The residual plots normally look quite awful because the residual distribution very often has two peaks, a negative and a positive one resulting from the binary nature of the outcome variable. However, it is still good to have a look at these plots using `plot(mod)`. At least the average should roughly be around zero and not show a trend. 
An often more informative plot to judge model fit for a binary logistic regression is to compare the fitted values with the data. To better see the observations, we slightly jitter them in the vertical direction.
If the model would fit the data well, the data would be, on average, equal to the fitted values. Thus, we add the $y = x$-line to the plot using the `abline` function with intercept 0 and slope 1.
Of course, binary data cannot lie on this line because they can only take on the two discrete values 0 or 1. However, the mean of the 0 and 1 values should lie on the line if the model fits well. Therefore, we calculate the mean for suitably selected classes of fitted values. In our example, we choose a class width of 0.1. Then, we calculate means per class and add these to the plot, together with a classical standard error that tells us how reliable the means are. This can be an indication whether our arbitrarily chosen class width is reasonable.

```{r lrgof, fig. cap=" Goodness of fit plot for the Bernoulli model fitted to little owl presence-absence data. Open circles = observed presence (1) or absence (0) jittered in the vertical direction; orange dots = mean (and 95% compatibility intervals given as vertical bards) of the observations within classes of width 0.1 along the x-axis. The dotted line indicates perfect coincidence between observation and fitted values. Orange larger points are from the model assuming a linear effect of elevation, wheras the smaller light blue points are from a model assuming a non-linear effect."}

plot(fitted(mod), jitter(anoctua$PA, amount=0.05), 
     xlab="Fitted values", ylab="Probability of presence", 
     las=1, cex.lab=1.2, cex=0.8)
abline(0,1, lty=3)

t.breaks <- cut(fitted(mod), seq(0,1, by=0.1))
means <- tapply(anoctua$PA, t.breaks, mean)
semean <- function(x) sd(x)/sqrt(length(x))
means.se <- tapply(anoctua$PA, t.breaks, semean)
points(seq(0.05, 0.95, by=0.1), means, pch=16, col="orange")
segments(seq(0.05, 0.95, by=0.1), means-2*means.se,
seq(0.05, 0.95,by=0.1), means+2*means.se,lwd=2, col="orange")

mod <- glm(PA ~ elevation + I(elevation^2) + I(elevation^3) +
             I(elevation^4), data=anoctua, family=binomial)
t.breaks <- cut(fitted(mod), seq(0,1, by=0.1))
means <- tapply(anoctua$PA, t.breaks, mean)
semean <- function(x) sd(x)/sqrt(length(x))
means.se <- tapply(anoctua$PA, t.breaks, semean)
points(seq(0.05, 0.95, by=0.1)+0.01, means, pch=16, col="lightblue", cex=0.7)
segments(seq(0.05, 0.95, by=0.1)+0.01, means-2*means.se,
seq(0.05, 0.95,by=0.1)+0.01, means+2*means.se,lwd=2, col="lightblue")


```


The means of the observed data (orange dots) do not fit well to the data (Figure \@ref(fig:lrgof)). For low presence probabilities, the model overestimates presence probabilities whereas, for medium presence probabilities, the model underestimates presence probability. This indicates that the relationship between little owl presence and elevation may not be linear. After including polynomials up to the fourth degree, we obtained a reasonable fit (light blue dots in Figure \@ref(fig:lrgof)). 

Now, we are ready to report and visualise the results. We can simulate the posterior distribution of $\beta_1$ and obtain the 95% compatibility interval.

```{r}
nsim <- 5000
bsim <- sim(mod, n.sim=nsim) # sim from package arm
apply(bsim@coef, 2, quantile, prob=c(0.5, 0.025, 0.975))
```

To interpret this polynomial function, an effect plot is helpful. To that end, and as we have done before, we calculate fitted values over the range of the covariate, together with compatibility intervals.

```{r}
newdat <- data.frame(elevation = seq(80,600,by=1))
Xmat <- model.matrix(~elevation+I(elevation^2)+I(elevation^3)+
                       I(elevation^4), data=newdat) # the model matrix
fitmat <- matrix(nrow=nrow(newdat), ncol=nsim)
for(i in 1:nsim) fitmat[,i] <- plogis(Xmat %*% bsim@coef[i,])
newdat$lwr <- apply(fitmat,1,quantile,probs=0.025)
newdat$fit <- plogis(Xmat %*% coef(mod))
newdat$upr <- apply(fitmat,1,quantile,probs=0.975)

```

We now can plot the data together with the estimate and its compatibility interval. We, again, use the function `jitter` to slightly scatter the points along the y-axis to make overlaying points visible.

```{r, fig.cap="Little owl presence data versus elevation with regression line and 95% compatibility interval (dotted lines). Open circles = observed presence (1) or abesnce (0) jittered in the vertical direction."}
plot(anoctua$elevation, jitter(anoctua$PA, amount=0.05), 
     las=1, cex.lab=1.4, cex.axis=1.2, xlab="Elevation",
     ylab="Probability of presence")
lines(newdat$elevation, newdat$fit, lwd=2)
lines(newdat$elevation, newdat$lwr, lty=3)
lines(newdat$elevation, newdat$upr, lty=3)
```


Binary data do not contain a lot of information. Therefore, large sample sizes are needed to obtain robust results.


Often presence/absence data are obtained by visiting plots several times during a distinct period, for example, a breeding period, and then it is reported whether a species has been seen or not. If it has been seen and if there is no misidentification in the data, it is present, however, if it has not been seen we
are usually not sure whether we have not detected it or whether it is absent. In the case of repeated visits to the same plot, it is possible to estimate the detection probability using occupancy models @MacKenzie.2002 or point count models @Royle.2004b. 
Finally, logistic regression can be used in the sense of a discriminant function analysis that aims to find predictors that discriminate members of two groups @Anderson.1974. However, if one wants to use the fitted value from such an analysis to assign group membership of a new subject, one has to take the prevalence of the two groups in the data into account. 


## Binomial model

The binomial model is usesd when the response variable is a count with an upper limit, e.g., the number of seeds that germinated among a total number of seeds, or the number of chicks hatching from the total number of eggs. Thus, we can use the binomial model always when the response is the sum of a predefined number of Bernoulli trials. Whether a seed germinates or not is a Bernoulli trial. If we have more than one seed, the number of germinated seeds follow a [binomial distribution](binomial-dist). 






## Poisson model
