<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>17 Model comparison and multimodel inference | Bayesian Data Analysis in Ecology with R and Stan</title>
  <meta name="description" content="This GitHub-book is a collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="17 Model comparison and multimodel inference | Bayesian Data Analysis in Ecology with R and Stan" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.jpg" />
  <meta property="og:description" content="This GitHub-book is a collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="github-repo" content="TobiasRoth/BDAEcology" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="17 Model comparison and multimodel inference | Bayesian Data Analysis in Ecology with R and Stan" />
  
  <meta name="twitter:description" content="This GitHub-book is a collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="twitter:image" content="/images/cover.jpg" />

<meta name="author" content="Fränzi Korner-Nievergelt, Tobias Roth, Stefanie von Felten, Jerôme Guélat, Bettina Almasi, Louis Hunninck, Pius Korner-Nievergelt" />


<meta name="date" content="2025-10-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelchecking.html"/>
<link rel="next" href="stan.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="settings/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i>Why this book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-contribute"><i class="fa fa-check"></i>How to contribute</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="part"><span><b>I BASIC STATISTICS FOR ECOLOGISTS</b></span></li>
<li class="chapter" data-level="1" data-path="PART-I.html"><a href="PART-I.html"><i class="fa fa-check"></i><b>1</b> Introduction to PART I</a>
<ul>
<li class="chapter" data-level="1.1" data-path="PART-I.html"><a href="PART-I.html#further-reading"><i class="fa fa-check"></i><b>1.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>2</b> Basics of statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="basics.html"><a href="basics.html#variables-and-observations"><i class="fa fa-check"></i><b>2.1</b> Variables and observations</a></li>
<li class="chapter" data-level="2.2" data-path="basics.html"><a href="basics.html#displaying-and-summarizing-data"><i class="fa fa-check"></i><b>2.2</b> Displaying and summarizing data</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="basics.html"><a href="basics.html#histogram"><i class="fa fa-check"></i><b>2.2.1</b> Histogram</a></li>
<li class="chapter" data-level="2.2.2" data-path="basics.html"><a href="basics.html#location-and-scatter"><i class="fa fa-check"></i><b>2.2.2</b> Location and scatter</a></li>
<li class="chapter" data-level="2.2.3" data-path="basics.html"><a href="basics.html#correlations"><i class="fa fa-check"></i><b>2.2.3</b> Correlations</a></li>
<li class="chapter" data-level="2.2.4" data-path="basics.html"><a href="basics.html#principal-components-analyses-pca"><i class="fa fa-check"></i><b>2.2.4</b> Principal components analyses PCA</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="basics.html"><a href="basics.html#inferential-statistics"><i class="fa fa-check"></i><b>2.3</b> Inferential statistics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="basics.html"><a href="basics.html#uncertainty"><i class="fa fa-check"></i><b>2.3.1</b> Uncertainty</a></li>
<li class="chapter" data-level="2.3.2" data-path="basics.html"><a href="basics.html#standard-error"><i class="fa fa-check"></i><b>2.3.2</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="basics.html"><a href="basics.html#bayes-theorem-and-the-common-aim-of-frequentist-and-bayesian-methods"><i class="fa fa-check"></i><b>2.4</b> Bayes theorem and the common aim of frequentist and Bayesian methods</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="basics.html"><a href="basics.html#bayes-theorem-for-discrete-events"><i class="fa fa-check"></i><b>2.4.1</b> Bayes theorem for discrete events</a></li>
<li class="chapter" data-level="2.4.2" data-path="basics.html"><a href="basics.html#bayes-theorem-for-continuous-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Bayes theorem for continuous parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="basics.html"><a href="basics.html#estimating-a-mean-assuming-that-the-variance-is-known"><i class="fa fa-check"></i><b>2.4.3</b> Estimating a mean assuming that the variance is known</a></li>
<li class="chapter" data-level="2.4.4" data-path="basics.html"><a href="basics.html#estimating-the-mean-and-the-variance"><i class="fa fa-check"></i><b>2.4.4</b> Estimating the mean and the variance</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="basics.html"><a href="basics.html#classical-frequentist-tests-and-alternatives"><i class="fa fa-check"></i><b>2.5</b> Classical frequentist tests and alternatives</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="basics.html"><a href="basics.html#nullhypothesis-testing"><i class="fa fa-check"></i><b>2.5.1</b> Nullhypothesis testing</a></li>
<li class="chapter" data-level="2.5.2" data-path="basics.html"><a href="basics.html#comparison-of-a-sample-with-a-fixed-value-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.2</b> Comparison of a sample with a fixed value (one-sample t-test)</a></li>
<li class="chapter" data-level="2.5.3" data-path="basics.html"><a href="basics.html#comparison-of-the-locations-between-two-groups-two-sample-t-test"><i class="fa fa-check"></i><b>2.5.3</b> Comparison of the locations between two groups (two-sample t-test)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="basics.html"><a href="basics.html#whyBayes"><i class="fa fa-check"></i><b>2.6</b> Comparing frequentist and Bayesian approach - an why we use Bayes</a></li>
<li class="chapter" data-level="2.7" data-path="basics.html"><a href="basics.html#summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analyses_steps.html"><a href="analyses_steps.html"><i class="fa fa-check"></i><b>3</b> Data analysis step by step</a>
<ul>
<li class="chapter" data-level="3.1" data-path="analyses_steps.html"><a href="analyses_steps.html#step1"><i class="fa fa-check"></i><b>3.1</b> Plausibility of data</a></li>
<li class="chapter" data-level="3.2" data-path="analyses_steps.html"><a href="analyses_steps.html#step2"><i class="fa fa-check"></i><b>3.2</b> Relationships</a></li>
<li class="chapter" data-level="3.3" data-path="analyses_steps.html"><a href="analyses_steps.html#step3"><i class="fa fa-check"></i><b>3.3</b> Data distribution</a></li>
<li class="chapter" data-level="3.4" data-path="analyses_steps.html"><a href="analyses_steps.html#step4"><i class="fa fa-check"></i><b>3.4</b> Preparation of explanatory variables</a></li>
<li class="chapter" data-level="3.5" data-path="analyses_steps.html"><a href="analyses_steps.html#step5"><i class="fa fa-check"></i><b>3.5</b> Data structure</a></li>
<li class="chapter" data-level="3.6" data-path="analyses_steps.html"><a href="analyses_steps.html#step6"><i class="fa fa-check"></i><b>3.6</b> Define prior distributions</a></li>
<li class="chapter" data-level="3.7" data-path="analyses_steps.html"><a href="analyses_steps.html#step7"><i class="fa fa-check"></i><b>3.7</b> Fit the model</a></li>
<li class="chapter" data-level="3.8" data-path="analyses_steps.html"><a href="analyses_steps.html#step8"><i class="fa fa-check"></i><b>3.8</b> Check model</a></li>
<li class="chapter" data-level="3.9" data-path="analyses_steps.html"><a href="analyses_steps.html#step9"><i class="fa fa-check"></i><b>3.9</b> Model uncertainty</a></li>
<li class="chapter" data-level="3.10" data-path="analyses_steps.html"><a href="analyses_steps.html#step10"><i class="fa fa-check"></i><b>3.10</b> Present model results</a></li>
<li class="chapter" data-level="" data-path="analyses_steps.html"><a href="analyses_steps.html#further-reading-1"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>4</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distributions.html"><a href="distributions.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="distributions.html"><a href="distributions.html#discrete-distributions"><i class="fa fa-check"></i><b>4.2</b> Discrete distributions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distributions.html"><a href="distributions.html#bernoulli-dist"><i class="fa fa-check"></i><b>4.2.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="4.2.2" data-path="distributions.html"><a href="distributions.html#binomial-dist"><i class="fa fa-check"></i><b>4.2.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="4.2.3" data-path="distributions.html"><a href="distributions.html#poisson"><i class="fa fa-check"></i><b>4.2.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="4.2.4" data-path="distributions.html"><a href="distributions.html#negative-binomial-distribution"><i class="fa fa-check"></i><b>4.2.4</b> Negative-binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distributions.html"><a href="distributions.html#continuous-distributions"><i class="fa fa-check"></i><b>4.3</b> Continuous distributions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distributions.html"><a href="distributions.html#beta-distribution"><i class="fa fa-check"></i><b>4.3.1</b> Beta distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="distributions.html"><a href="distributions.html#normdist"><i class="fa fa-check"></i><b>4.3.2</b> Normal distribution</a></li>
<li class="chapter" data-level="4.3.3" data-path="distributions.html"><a href="distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>4.3.3</b> Gamma distribution</a></li>
<li class="chapter" data-level="4.3.4" data-path="distributions.html"><a href="distributions.html#cauchydistri"><i class="fa fa-check"></i><b>4.3.4</b> Cauchy distribution</a></li>
<li class="chapter" data-level="4.3.5" data-path="distributions.html"><a href="distributions.html#t-distribution"><i class="fa fa-check"></i><b>4.3.5</b> t-distribution</a></li>
<li class="chapter" data-level="4.3.6" data-path="distributions.html"><a href="distributions.html#f-distribution"><i class="fa fa-check"></i><b>4.3.6</b> F-distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="transformations.html"><a href="transformations.html"><i class="fa fa-check"></i><b>5</b> Transformations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="transformations.html"><a href="transformations.html#some-r-specific-aspects"><i class="fa fa-check"></i><b>5.1</b> Some R-specific aspects</a></li>
<li class="chapter" data-level="5.2" data-path="transformations.html"><a href="transformations.html#first-aid-transformations"><i class="fa fa-check"></i><b>5.2</b> First-aid transformations</a></li>
<li class="chapter" data-level="5.3" data-path="transformations.html"><a href="transformations.html#logtransformation"><i class="fa fa-check"></i><b>5.3</b> Log-transformation with Stahel</a></li>
<li class="chapter" data-level="5.4" data-path="transformations.html"><a href="transformations.html#ztransformation"><i class="fa fa-check"></i><b>5.4</b> Centering and scaling (z-transformation)</a></li>
<li class="chapter" data-level="5.5" data-path="transformations.html"><a href="transformations.html#transformationspolynomials"><i class="fa fa-check"></i><b>5.5</b> Raw and orthogonal polynomials</a></li>
<li class="chapter" data-level="5.6" data-path="transformations.html"><a href="transformations.html#square-root-transformation"><i class="fa fa-check"></i><b>5.6</b> Square-root transformation</a></li>
<li class="chapter" data-level="5.7" data-path="transformations.html"><a href="transformations.html#arcsinus-square-root-transformation"><i class="fa fa-check"></i><b>5.7</b> Arcsinus-square-root transformation</a></li>
<li class="chapter" data-level="5.8" data-path="transformations.html"><a href="transformations.html#logit-transformation"><i class="fa fa-check"></i><b>5.8</b> Logit transformation</a></li>
<li class="chapter" data-level="5.9" data-path="transformations.html"><a href="transformations.html#categorizing-and-decategorizing"><i class="fa fa-check"></i><b>5.9</b> Categorizing and decategorizing</a></li>
<li class="chapter" data-level="5.10" data-path="transformations.html"><a href="transformations.html#transformationscircular"><i class="fa fa-check"></i><b>5.10</b> Sinus and cosinus transformation for circular variables</a></li>
<li class="chapter" data-level="5.11" data-path="transformations.html"><a href="transformations.html#cloglog-probit-inverse-transformation"><i class="fa fa-check"></i><b>5.11</b> Cloglog, probit, inverse transformation</a></li>
<li class="chapter" data-level="5.12" data-path="transformations.html"><a href="transformations.html#identity-transformation"><i class="fa fa-check"></i><b>5.12</b> Identity transformation</a></li>
<li class="chapter" data-level="5.13" data-path="transformations.html"><a href="transformations.html#transformations-on-the-outcome-variable"><i class="fa fa-check"></i><b>5.13</b> Transformations on the outcome variable</a></li>
<li class="chapter" data-level="5.14" data-path="transformations.html"><a href="transformations.html#back-transformation"><i class="fa fa-check"></i><b>5.14</b> Back-transformation</a></li>
<li class="chapter" data-level="5.15" data-path="transformations.html"><a href="transformations.html#applythesametransformation"><i class="fa fa-check"></i><b>5.15</b> Applying the transformations to new data</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="reproducibleresearch.html"><a href="reproducibleresearch.html"><i class="fa fa-check"></i><b>6</b> Reproducible research</a>
<ul>
<li class="chapter" data-level="6.1" data-path="reproducibleresearch.html"><a href="reproducibleresearch.html#summary-1"><i class="fa fa-check"></i><b>6.1</b> Summary</a></li>
<li class="chapter" data-level="6.2" data-path="reproducibleresearch.html"><a href="reproducibleresearch.html#further-reading-2"><i class="fa fa-check"></i><b>6.2</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="furthertopics.html"><a href="furthertopics.html"><i class="fa fa-check"></i><b>7</b> Further topics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="furthertopics.html"><a href="furthertopics.html#bioacoustic-analyse"><i class="fa fa-check"></i><b>7.1</b> Bioacoustic analyse</a></li>
<li class="chapter" data-level="7.2" data-path="furthertopics.html"><a href="furthertopics.html#python"><i class="fa fa-check"></i><b>7.2</b> Python</a></li>
<li class="chapter" data-level="7.3" data-path="furthertopics.html"><a href="furthertopics.html#some-r"><i class="fa fa-check"></i><b>7.3</b> Some R</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="furthertopics.html"><a href="furthertopics.html#date-on-x-axis"><i class="fa fa-check"></i><b>7.3.1</b> Date on x-axis</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II BAYESIAN DATA ANALYSIS</b></span></li>
<li class="chapter" data-level="8" data-path="PART-II.html"><a href="PART-II.html"><i class="fa fa-check"></i><b>8</b> Introduction to PART II</a>
<ul>
<li class="chapter" data-level="" data-path="PART-II.html"><a href="PART-II.html#further-reading-3"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html"><i class="fa fa-check"></i><b>9</b> The Bayesian paradigm and likelihood in a frequentist and Bayesian framework</a>
<ul>
<li class="chapter" data-level="9.1" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#short-historical-overview"><i class="fa fa-check"></i><b>9.1</b> Short historical overview</a></li>
<li class="chapter" data-level="9.2" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#the-bayesian-way"><i class="fa fa-check"></i><b>9.2</b> The Bayesian way</a></li>
<li class="chapter" data-level="9.3" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#likelihood"><i class="fa fa-check"></i><b>9.3</b> Likelihood</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#theory"><i class="fa fa-check"></i><b>9.3.1</b> Theory</a></li>
<li class="chapter" data-level="9.3.2" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#the-maximum-likelihood-method"><i class="fa fa-check"></i><b>9.3.2</b> The maximum likelihood method</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#the-log-pointwise-predictive-density"><i class="fa fa-check"></i><b>9.4</b> The log pointwise predictive density</a></li>
<li class="chapter" data-level="9.5" data-path="bayesian_paradigm.html"><a href="bayesian_paradigm.html#further-reading-4"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>10</b> Prior distributions and prior sensitivity analyses</a>
<ul>
<li class="chapter" data-level="10.1" data-path="priors.html"><a href="priors.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="priors.html"><a href="priors.html#choosepriors"><i class="fa fa-check"></i><b>10.2</b> How to choose a prior</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="priors.html"><a href="priors.html#priors-for-variance-parameters"><i class="fa fa-check"></i><b>10.2.1</b> Priors for variance parameters</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="priors.html"><a href="priors.html#prior-sensitivity"><i class="fa fa-check"></i><b>10.3</b> Prior sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>11</b> Normal Linear Models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lm.html"><a href="lm.html#linear-regression"><i class="fa fa-check"></i><b>11.1</b> Linear regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="lm.html"><a href="lm.html#background"><i class="fa fa-check"></i><b>11.1.1</b> Background</a></li>
<li class="chapter" data-level="11.1.2" data-path="lm.html"><a href="lm.html#fitting-a-linear-regression-in-r"><i class="fa fa-check"></i><b>11.1.2</b> Fitting a linear regression in R</a></li>
<li class="chapter" data-level="11.1.3" data-path="lm.html"><a href="lm.html#presenting-the-results"><i class="fa fa-check"></i><b>11.1.3</b> Presenting the results</a></li>
<li class="chapter" data-level="11.1.4" data-path="lm.html"><a href="lm.html#interpretation-of-the-r-summary-output"><i class="fa fa-check"></i><b>11.1.4</b> Interpretation of the R summary output</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="lm.html"><a href="lm.html#linear-model-with-one-categorical-predictor-one-way-anova"><i class="fa fa-check"></i><b>11.2</b> Linear model with one categorical predictor (one-way ANOVA)</a></li>
<li class="chapter" data-level="11.3" data-path="lm.html"><a href="lm.html#other-variants-of-normal-linear-models"><i class="fa fa-check"></i><b>11.3</b> Other variants of normal linear models</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="lm.html"><a href="lm.html#twowayanova"><i class="fa fa-check"></i><b>11.3.1</b> Linear model with two categorical predictors (two-way ANOVA)</a></li>
<li class="chapter" data-level="11.3.2" data-path="lm.html"><a href="lm.html#a-linear-model-with-a-categorical-and-a-numeric-predictor-ancova"><i class="fa fa-check"></i><b>11.3.2</b> A linear model with a categorical and a numeric predictor (ANCOVA)</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="lm.html"><a href="lm.html#collinearity"><i class="fa fa-check"></i><b>11.4</b> Partial coefficients and some comments on collinearity</a></li>
<li class="chapter" data-level="11.5" data-path="lm.html"><a href="lm.html#orderedfactors"><i class="fa fa-check"></i><b>11.5</b> Ordered factors and contrasts</a></li>
<li class="chapter" data-level="11.6" data-path="lm.html"><a href="lm.html#lmpolynomials"><i class="fa fa-check"></i><b>11.6</b> Quadratic and higher polynomial terms</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="residualanalysis.html"><a href="residualanalysis.html"><i class="fa fa-check"></i><b>12</b> Assessing model assumptions</a>
<ul>
<li class="chapter" data-level="12.1" data-path="residualanalysis.html"><a href="residualanalysis.html#model-assumptions"><i class="fa fa-check"></i><b>12.1</b> Model assumptions</a></li>
<li class="chapter" data-level="12.2" data-path="residualanalysis.html"><a href="residualanalysis.html#independent-and-identically-distributed"><i class="fa fa-check"></i><b>12.2</b> Independent and identically distributed</a></li>
<li class="chapter" data-level="12.3" data-path="residualanalysis.html"><a href="residualanalysis.html#qqplot"><i class="fa fa-check"></i><b>12.3</b> The QQ-plot</a></li>
<li class="chapter" data-level="12.4" data-path="residualanalysis.html"><a href="residualanalysis.html#tempautocorrelation"><i class="fa fa-check"></i><b>12.4</b> Temporal autocorrelation</a></li>
<li class="chapter" data-level="12.5" data-path="residualanalysis.html"><a href="residualanalysis.html#spatialautocorrelation"><i class="fa fa-check"></i><b>12.5</b> Spatial autocorrelation</a></li>
<li class="chapter" data-level="12.6" data-path="residualanalysis.html"><a href="residualanalysis.html#Heteroscedasticity"><i class="fa fa-check"></i><b>12.6</b> Heteroscedasticity</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="lmer.html"><a href="lmer.html"><i class="fa fa-check"></i><b>13</b> Linear mixed effect models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="lmer.html"><a href="lmer.html#background-2"><i class="fa fa-check"></i><b>13.1</b> Background</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="lmer.html"><a href="lmer.html#why-mixed-effects-models"><i class="fa fa-check"></i><b>13.1.1</b> Why mixed effects models?</a></li>
<li class="chapter" data-level="13.1.2" data-path="lmer.html"><a href="lmer.html#random-factors-and-partial-pooling"><i class="fa fa-check"></i><b>13.1.2</b> Random factors and partial pooling</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="lmer.html"><a href="lmer.html#fitting-a-normal-linear-mixed-model-in-r"><i class="fa fa-check"></i><b>13.2</b> Fitting a normal linear mixed model in R</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="lmer.html"><a href="lmer.html#background-3"><i class="fa fa-check"></i><b>13.2.1</b> Background</a></li>
<li class="chapter" data-level="13.2.2" data-path="lmer.html"><a href="lmer.html#fitting-a-normal-linear-mixed-model-using-lmer"><i class="fa fa-check"></i><b>13.2.2</b> Fitting a normal linear mixed model using lmer</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="lmer.html"><a href="lmer.html#restricted-maximum-likelihood-estimation-reml"><i class="fa fa-check"></i><b>13.3</b> Restricted maximum likelihood estimation (REML)</a></li>
<li class="chapter" data-level="13.4" data-path="lmer.html"><a href="lmer.html#assessing-model-assumptions"><i class="fa fa-check"></i><b>13.4</b> Assessing model assumptions</a></li>
<li class="chapter" data-level="13.5" data-path="lmer.html"><a href="lmer.html#presenting-the-results-1"><i class="fa fa-check"></i><b>13.5</b> Presenting the results</a></li>
<li class="chapter" data-level="13.6" data-path="lmer.html"><a href="lmer.html#random-intercept-and-slope"><i class="fa fa-check"></i><b>13.6</b> Random intercept and slope</a></li>
<li class="chapter" data-level="13.7" data-path="lmer.html"><a href="lmer.html#nested-and-crossed-random-effects"><i class="fa fa-check"></i><b>13.7</b> Nested and crossed random effects</a></li>
<li class="chapter" data-level="13.8" data-path="lmer.html"><a href="lmer.html#model-selection-in-mixed-models"><i class="fa fa-check"></i><b>13.8</b> Model selection in mixed models</a></li>
<li class="chapter" data-level="13.9" data-path="lmer.html"><a href="lmer.html#further-reading-5"><i class="fa fa-check"></i><b>13.9</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>14</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="glm.html"><a href="glm.html#introduction-2"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="glm.html"><a href="glm.html#bernoulli-model"><i class="fa fa-check"></i><b>14.2</b> Bernoulli model</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="glm.html"><a href="glm.html#background-4"><i class="fa fa-check"></i><b>14.2.1</b> Background</a></li>
<li class="chapter" data-level="14.2.2" data-path="glm.html"><a href="glm.html#fitting-a-bernoulli-model-in-r"><i class="fa fa-check"></i><b>14.2.2</b> Fitting a Bernoulli model in R</a></li>
<li class="chapter" data-level="14.2.3" data-path="glm.html"><a href="glm.html#assessing-model-assumptions-in-a-bernoulli-model"><i class="fa fa-check"></i><b>14.2.3</b> Assessing model assumptions in a Bernoulli model</a></li>
<li class="chapter" data-level="14.2.4" data-path="glm.html"><a href="glm.html#visualising-the-results"><i class="fa fa-check"></i><b>14.2.4</b> Visualising the results</a></li>
<li class="chapter" data-level="14.2.5" data-path="glm.html"><a href="glm.html#some-remarks"><i class="fa fa-check"></i><b>14.2.5</b> Some remarks</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="glm.html"><a href="glm.html#binomial-model"><i class="fa fa-check"></i><b>14.3</b> Binomial model</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="glm.html"><a href="glm.html#background-5"><i class="fa fa-check"></i><b>14.3.1</b> Background</a></li>
<li class="chapter" data-level="14.3.2" data-path="glm.html"><a href="glm.html#fitting-a-binomial-model-in-r"><i class="fa fa-check"></i><b>14.3.2</b> Fitting a binomial model in R</a></li>
<li class="chapter" data-level="14.3.3" data-path="glm.html"><a href="glm.html#assessing-assumptions-in-a-binomial-model"><i class="fa fa-check"></i><b>14.3.3</b> Assessing assumptions in a binomial model</a></li>
<li class="chapter" data-level="14.3.4" data-path="glm.html"><a href="glm.html#visualising-the-results-1"><i class="fa fa-check"></i><b>14.3.4</b> Visualising the results</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="glm.html"><a href="glm.html#poisson-model"><i class="fa fa-check"></i><b>14.4</b> Poisson model</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="glm.html"><a href="glm.html#background-6"><i class="fa fa-check"></i><b>14.4.1</b> Background</a></li>
<li class="chapter" data-level="14.4.2" data-path="glm.html"><a href="glm.html#fitting-a-poisson-model-in-r"><i class="fa fa-check"></i><b>14.4.2</b> Fitting a Poisson model in R</a></li>
<li class="chapter" data-level="14.4.3" data-path="glm.html"><a href="glm.html#assessing-model-assumptions-1"><i class="fa fa-check"></i><b>14.4.3</b> Assessing model assumptions</a></li>
<li class="chapter" data-level="14.4.4" data-path="glm.html"><a href="glm.html#visualising-results"><i class="fa fa-check"></i><b>14.4.4</b> Visualising results</a></li>
<li class="chapter" data-level="14.4.5" data-path="glm.html"><a href="glm.html#modeling-rates-and-densities-poisson-model-with-an-offset"><i class="fa fa-check"></i><b>14.4.5</b> Modeling rates and densities: Poisson model with an offset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="glmm.html"><a href="glmm.html"><i class="fa fa-check"></i><b>15</b> Generalized linear mixed models</a>
<ul>
<li class="chapter" data-level="15.1" data-path="glmm.html"><a href="glmm.html#background-7"><i class="fa fa-check"></i><b>15.1</b> Background</a></li>
<li class="chapter" data-level="15.2" data-path="glmm.html"><a href="glmm.html#binomial-mixed-model"><i class="fa fa-check"></i><b>15.2</b> Binomial mixed model</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="glmm.html"><a href="glmm.html#background-8"><i class="fa fa-check"></i><b>15.2.1</b> Background</a></li>
<li class="chapter" data-level="15.2.2" data-path="glmm.html"><a href="glmm.html#fitting-a-binomial-mixed-model-in-r"><i class="fa fa-check"></i><b>15.2.2</b> Fitting a binomial mixed model in R</a></li>
<li class="chapter" data-level="15.2.3" data-path="glmm.html"><a href="glmm.html#presenting-the-results-2"><i class="fa fa-check"></i><b>15.2.3</b> Presenting the results</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="glmm.html"><a href="glmm.html#poisson-mixed-model"><i class="fa fa-check"></i><b>15.3</b> Poisson mixed model</a></li>
<li class="chapter" data-level="15.4" data-path="glmm.html"><a href="glmm.html#summary-2"><i class="fa fa-check"></i><b>15.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="modelchecking.html"><a href="modelchecking.html"><i class="fa fa-check"></i><b>16</b> Posterior predictive model checking</a></li>
<li class="chapter" data-level="17" data-path="model_comparison.html"><a href="model_comparison.html"><i class="fa fa-check"></i><b>17</b> Model comparison and multimodel inference</a>
<ul>
<li class="chapter" data-level="17.1" data-path="model_comparison.html"><a href="model_comparison.html#when-and-why-we-compare-models-and-why-model-selection-is-difficult"><i class="fa fa-check"></i><b>17.1</b> When and why we compare models and why model selection is difficult</a></li>
<li class="chapter" data-level="17.2" data-path="model_comparison.html"><a href="model_comparison.html#methods-for-model-commparison"><i class="fa fa-check"></i><b>17.2</b> Methods for model commparison</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="model_comparison.html"><a href="model_comparison.html#cross-validation"><i class="fa fa-check"></i><b>17.2.1</b> Cross-validation</a></li>
<li class="chapter" data-level="17.2.2" data-path="model_comparison.html"><a href="model_comparison.html#information-criteria-akaike-information-criterion-and-widely-applicable-information-criterion"><i class="fa fa-check"></i><b>17.2.2</b> Information criteria: Akaike information criterion and widely applicable information criterion</a></li>
<li class="chapter" data-level="17.2.3" data-path="model_comparison.html"><a href="model_comparison.html#other-information-criteria"><i class="fa fa-check"></i><b>17.2.3</b> Other information criteria</a></li>
<li class="chapter" data-level="17.2.4" data-path="model_comparison.html"><a href="model_comparison.html#bayes-factors-and-posterior-model-probabilities"><i class="fa fa-check"></i><b>17.2.4</b> Bayes factors and posterior model probabilities</a></li>
<li class="chapter" data-level="17.2.5" data-path="model_comparison.html"><a href="model_comparison.html#model-based-methods-to-obtain-posterior-model-probabilities-and-inclusion-probabilities"><i class="fa fa-check"></i><b>17.2.5</b> Model-based methods to obtain posterior model probabilities and inclusion probabilities</a></li>
<li class="chapter" data-level="17.2.6" data-path="model_comparison.html"><a href="model_comparison.html#least-absolute-shrinkage-and-selection-operator-lasso-and-ridge-regression"><i class="fa fa-check"></i><b>17.2.6</b> Least absolute shrinkage and selection operator (LASSO) and ridge regression</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="model_comparison.html"><a href="model_comparison.html#multimodel-inference"><i class="fa fa-check"></i><b>17.3</b> Multimodel inference</a></li>
<li class="chapter" data-level="17.4" data-path="model_comparison.html"><a href="model_comparison.html#which-method-to-choose-and-which-strategy-to-follow"><i class="fa fa-check"></i><b>17.4</b> Which method to choose and which strategy to follow?</a></li>
<li class="chapter" data-level="17.5" data-path="model_comparison.html"><a href="model_comparison.html#further-reading-6"><i class="fa fa-check"></i><b>17.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>18</b> MCMC using Stan via rstanarm, brms or rstan</a>
<ul>
<li class="chapter" data-level="18.1" data-path="stan.html"><a href="stan.html#background-9"><i class="fa fa-check"></i><b>18.1</b> Background</a></li>
<li class="chapter" data-level="18.2" data-path="stan.html"><a href="stan.html#assessing-convergence-of-the-markov-chains-and-trouble-shooting-warnings-of-stan"><i class="fa fa-check"></i><b>18.2</b> Assessing convergence of the Markov chains and trouble shooting warnings of Stan</a></li>
<li class="chapter" data-level="18.3" data-path="stan.html"><a href="stan.html#using-stan-via-rstan"><i class="fa fa-check"></i><b>18.3</b> Using Stan via rstan</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="stan.html"><a href="stan.html#firststanmod"><i class="fa fa-check"></i><b>18.3.1</b> Writing a Stan model</a></li>
<li class="chapter" data-level="18.3.2" data-path="stan.html"><a href="stan.html#run-stan-from-r-using-rstan"><i class="fa fa-check"></i><b>18.3.2</b> Run Stan from R using rstan</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#further-reading-7"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ridge_regression.html"><a href="ridge_regression.html"><i class="fa fa-check"></i><b>19</b> Ridge Regression</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ridge_regression.html"><a href="ridge_regression.html#introduction-3"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="SEM.html"><a href="SEM.html"><i class="fa fa-check"></i><b>20</b> Structural equation models</a>
<ul>
<li class="chapter" data-level="20.1" data-path="SEM.html"><a href="SEM.html#introduction-4"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="spatial_glmm.html"><a href="spatial_glmm.html"><i class="fa fa-check"></i><b>21</b> Modeling spatial data using GLMM</a>
<ul>
<li class="chapter" data-level="21.1" data-path="spatial_glmm.html"><a href="spatial_glmm.html#introduction-5"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="spatial_glmm.html"><a href="spatial_glmm.html#summary-3"><i class="fa fa-check"></i><b>21.2</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III ECOLOGICAL MODELS</b></span></li>
<li class="chapter" data-level="22" data-path="PART-III.html"><a href="PART-III.html"><i class="fa fa-check"></i><b>22</b> Introduction to PART III</a>
<ul>
<li class="chapter" data-level="22.1" data-path="PART-III.html"><a href="PART-III.html#model-notations"><i class="fa fa-check"></i><b>22.1</b> Model notations</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html"><i class="fa fa-check"></i><b>23</b> Zero-inflated Poisson mixed model</a>
<ul>
<li class="chapter" data-level="23.1" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#introduction-6"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#example-data"><i class="fa fa-check"></i><b>23.2</b> Example data</a></li>
<li class="chapter" data-level="23.3" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#model"><i class="fa fa-check"></i><b>23.3</b> Model</a></li>
<li class="chapter" data-level="23.4" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#further-packages-and-readings"><i class="fa fa-check"></i><b>23.4</b> Further packages and readings</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="dailynestsurv.html"><a href="dailynestsurv.html"><i class="fa fa-check"></i><b>24</b> Daily nest survival</a>
<ul>
<li class="chapter" data-level="24.1" data-path="dailynestsurv.html"><a href="dailynestsurv.html#background-10"><i class="fa fa-check"></i><b>24.1</b> Background</a></li>
<li class="chapter" data-level="24.2" data-path="dailynestsurv.html"><a href="dailynestsurv.html#models-for-estimating-daily-nest-survival"><i class="fa fa-check"></i><b>24.2</b> Models for estimating daily nest survival</a></li>
<li class="chapter" data-level="24.3" data-path="dailynestsurv.html"><a href="dailynestsurv.html#known-fate-model"><i class="fa fa-check"></i><b>24.3</b> Known fate model</a></li>
<li class="chapter" data-level="24.4" data-path="dailynestsurv.html"><a href="dailynestsurv.html#dailynestsurvstan"><i class="fa fa-check"></i><b>24.4</b> The Stan model</a></li>
<li class="chapter" data-level="24.5" data-path="dailynestsurv.html"><a href="dailynestsurv.html#prepare-data-and-run-stan"><i class="fa fa-check"></i><b>24.5</b> Prepare data and run Stan</a></li>
<li class="chapter" data-level="24.6" data-path="dailynestsurv.html"><a href="dailynestsurv.html#check-convergence"><i class="fa fa-check"></i><b>24.6</b> Check convergence</a></li>
<li class="chapter" data-level="24.7" data-path="dailynestsurv.html"><a href="dailynestsurv.html#look-at-results"><i class="fa fa-check"></i><b>24.7</b> Look at results</a></li>
<li class="chapter" data-level="24.8" data-path="dailynestsurv.html"><a href="dailynestsurv.html#known-fate-model-for-irregular-nest-controls"><i class="fa fa-check"></i><b>24.8</b> Known fate model for irregular nest controls</a></li>
<li class="chapter" data-level="" data-path="dailynestsurv.html"><a href="dailynestsurv.html#further-reading-8"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html"><i class="fa fa-check"></i><b>25</b> Capture-mark recapture model with a mixture structure to account for missing sex-variable for parts of the individuals</a>
<ul>
<li class="chapter" data-level="25.1" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html#introduction-7"><i class="fa fa-check"></i><b>25.1</b> Introduction</a></li>
<li class="chapter" data-level="25.2" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html#data-description"><i class="fa fa-check"></i><b>25.2</b> Data description</a></li>
<li class="chapter" data-level="25.3" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html#model-description"><i class="fa fa-check"></i><b>25.3</b> Model description</a></li>
<li class="chapter" data-level="25.4" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html#the-stan-code"><i class="fa fa-check"></i><b>25.4</b> The Stan code</a></li>
<li class="chapter" data-level="25.5" data-path="cjs_with_mix.html"><a href="cjs_with_mix.html#call-stan-from-r-check-convergence-and-look-at-results"><i class="fa fa-check"></i><b>25.5</b> Call Stan from R, check convergence and look at results</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="samplesize.html"><a href="samplesize.html"><i class="fa fa-check"></i><b>26</b> What sample size?</a>
<ul>
<li class="chapter" data-level="26.1" data-path="samplesize.html"><a href="samplesize.html#introduction-8"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>IV APPENDICES</b></span></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
<li class="divider"></li>
</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Data Analysis in Ecology with R and Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model_comparison" class="section level1 hasAnchor" number="17">
<h1><span class="header-section-number">17</span> Model comparison and multimodel inference<a href="model_comparison.html#model_comparison" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!--Draft of Fraenzi 1.10.2024-->
<div id="when-and-why-we-compare-models-and-why-model-selection-is-difficult" class="section level2 hasAnchor" number="17.1">
<h2><span class="header-section-number">17.1</span> When and why we compare models and why model selection is difficult<a href="model_comparison.html#when-and-why-we-compare-models-and-why-model-selection-is-difficult" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Model selection and multimodel inference are delicate topics! During the data analysis process we sometimes come to a point where we have more than one model that adequately describes the data (according to <a href="residualanalysis.html#residualanalysis">residual analyses</a> and <a href="modelchecking.html#modelchecking">posterior predictive model checking</a>), and that are potentially interpretable in a sensible way. The more complex a model is, the better it fits the data and residual plots and predictive model checking look even better. But, at what point do we want to stop adding complexity? There is no unique answer to this question, except that the choice of a model is central to science, and that this choice may be based on expert knowledge on the mechanisms that have produced the data. Mathematical criteria may help in finding a useful model, however, they may also misguide researchers <span class="citation">(<a href="referenzen.html#ref-Bornmann.2024">Bornmann and Marewski 2024</a>)</span>. Scientists should build meaningful models based on their experience of the subject. Consequently, thinking about the processes that have generated the data is a central aspect of model selection <span class="citation">(e.g. <a href="referenzen.html#ref-Gelman.1999">A. Gelman and Rubin 1999</a>; <a href="referenzen.html#ref-Anderson.2008">D. R. Anderson 2008</a>; <a href="referenzen.html#ref-Claeskens.2008">Claeskens and Hjort 2008</a>; <a href="referenzen.html#ref-Link.2010">Link and Barker 2010</a>; <a href="referenzen.html#ref-Gelman.2014">A. Gelman et al. 2014</a>; and many more)</span>.
Why is model selection difficult? With increasing complexity of the model, the bias (i.e., the systematic difference between a parameter estimate and its true values) decreases, whereas the uncertainty of the parameter estimates increases. To reduce bias, we would like to increase the complexity of the model (e.g., by increasing the number of predictors and building more realistic models) but with models that are too complex (compared to sample size) the uncertainty in the parameter estimates becomes so large that the model will not be useful. Hence, if the process studied is complex, a large sample size is needed. However, sample sizes are usually low compared to the complexity of the processes that have generated them. Then, less complex models may capture the information in the data, at least for some of the processes, more clearly than a model too complex for the data at hand. Where the optimum in the trade-off between bias and uncertainty lies depends on the purpose and the context of the study. In some studies, it is extremely important to keep bias small, whereas in other studies high precision is more useful. The first type of models are sometimes called “confirmatory” and the latter “predictive” <span class="citation">(<a href="referenzen.html#ref-Shmueli.2010">Shmueli 2010</a>)</span>. Mathematical techniques for selecting a model or for basing the inference on several models simultaneously (multimodel inference) are particularly helpful for constructing predictive models. For example, estimation of the total population of wallcreepers <em>Tichodroma muraria</em> in Switzerland may be done based on a habitat model fitted to population count data on a sample of 1 km2 plots (e.g., from a monitoring program). The purpose of the model is to predict wallcreeper abundance for the non-sampled plots. The sum of the predicted abundances over all plots gives an estimate for the total population of wallcreepers in Switzerland. The aim of the model in this example is to produce precise predictions. Therefore, we aim at selecting, among the available habitat variables, the ones that produce the most reliable predictions of wallcreeper abundance. In this case, the predictive performance of a model is more important than the estimation of unbiased effect sizes, hence, we aim at reducing the uncertainty of the estimates, rather than including all possible relevant predictors. Many of the widely available habitat variables will not have a direct relationship with the biology of the wallcreeper and their estimated effect sizes will be difficult to interpret anyway. Therefore, it is less of a problem when the estimated effects are biased as long as the predictions are reliable.</p>
<p>In contrast, in a study that aims at better understanding a system, for example, when we are interested in how temperature influences the timing of breeding in the snowfinch, it is important to measure the effect of temperature on the timing of the broods with minimal bias, i.e. corrected for other environmental influences such as snow conditions. Because bias decreases the more realistic the model is, we may prefer to use more complex models in such cases. Then, we would use predictive model checking and biological reasoning about the process that generated the data, rather than a mathematical criterion that measures the predictive performance of a model. Using the latter method, final models often contain structures (e.g. fixed effects) that are only characteristic for the specific data set but have no general validity (even if out-of-data predictive performance has been used, the model is still fitted to a finite number of observations).<br />
Theoretically, we should construct the model before looking at the data. However, to do so, we need to know the system that we study in advance, which may be difficult since we often collect data to learn about the system in the first place.<br />
Bias enters in scientific studies at many places ranging from what questions we ask, to the tools that are available for data collection, to the way we present the results. The data we collect are the ones we think are important (or the ones that can be logistically and physically collected) but not the ones that may be relevant in the system. A non-biased study therefore may be one that does not start with a question, where exceptionally all data are collected and then mathematical criteria are used to sort out the relationships. Of course, it is impossible to collect data for all factors relevant to the system. Therefore, we formulate specific questions and carefully design our study, at the cost of introducing bias due to the way we think about the system. Selecting models after having collected the data introduces another bias. At this stage, the bias is due to specificity of the data (overfit). But sometimes it is useful to reduce model complexity by a formal model selection or multimodel inference method. Table 11-1 lists some situations that evoke a model selection or multimodel inference problem and how we may address the problem.<br />
The out-of-data predictive performance of a model is certainly very important in studies such as the preceding wallcreeper example. But also in basic research studies measurements of the predictive performance can help in understanding a model. A model that is too simple will lead us to make poor predictions in many cases because it does not account for all important processes, whereas a too complex model (compared to the sample size) will make poor predictions because parameter estimates are uncertain. Unfortunately (or fortunately?), there does not yet exist a single method for measuring predictive performance that is generally considered the gold standard. That makes model selection difficult. Here, we try to summarize and present some methods that we found useful for specific problems. A plenitude of articles and books discuss model selection and multimodel inference much more exhaustively than we do here.</p>
<table>
<caption><span id="tab:modsel">Table 17.1: </span> Situations (after residual analyses and predictive model checking) that evoke model selection or multi-model inference with methods that we consider in the specific situation. This list is neither intended to be exhaustive nor dogmatic.</caption>
<colgroup>
<col width="52%" />
<col width="47%" />
</colgroup>
<thead>
<tr>
<th align="left">Situation</th>
<th align="left">Useful method</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Describe a nonlinear effect using polynomials: How many polynomials should be included?</td>
<td align="left">WAIC, or cross-validation; consider using a GAM(M) or non-linear model</td>
</tr>
<tr>
<td align="left">Finding an appropriate smoothness in GAM(M)</td>
<td align="left">cross-validation, WAIC</td>
</tr>
<tr>
<td align="left">Omit interactions from a model for better interpretability</td>
<td align="left">Decide whether the interaction is biologically relevant, compare effect sizes, or use WAIC, or cross-validation</td>
</tr>
<tr>
<td align="left">Computing problems that may be produced by too many random factors: which random factor should be deleted?</td>
<td align="left">Assess the importance of the random factors by visualising among-group variance in plots or by fitting the model using Bayesian methods (priors may help fitting the model). Do not delete random factors when there was a good reason to include them. Also, WAIC may be helpful.</td>
</tr>
<tr>
<td align="left">The residuals are spatially correlated and no theory about the shape of the correlation function exists: choose a correlation function (e.g., linear, exponential, spherical)</td>
<td align="left">WAIC may help, but as it has difficulties in structured models, such as spatial models <span class="citation">(<a href="referenzen.html#ref-Gelman.2014">A. Gelman et al. 2014</a>)</span>, AIC may be a pragmatic alternative. Use predictive model-checking to see which model best captures the data’s spatial distribution.</td>
</tr>
<tr>
<td align="left">Different models represent different biological hypotheses, which mutually exclude each other. It should be measured which one has the highest support given the data</td>
<td align="left">Bayes factor and posterior model probabilities are nice tools for that. However, results are more easily interpreted if prior information is available. In case of no prior information, WAIC may be a better alternative. If the interest is in derived parameters (e.g., fitted values, predictions, population estimates), model averaging may be considered.</td>
</tr>
<tr>
<td align="left">Many explanatory variables and only the important ones should be included to reduce uncertainty</td>
<td align="left">Do not remove variables of interest (aim of the study) from the model. For nuisance variables, cross-validation, WAIC, LASSO, ridge regression, or inclusion probabilities may be useful. Choose method depending on the purpose of the study.</td>
</tr>
<tr>
<td align="left">There are more explanatory variables than observations</td>
<td align="left">LASSO and ridge regression may be helpful.</td>
</tr>
</tbody>
</table>
<p>In many cases, models have specific purposes. Based on results from a statistical model, decisions are made and actions are started. These decisions and actions are associated with benefits and risks. The benefits and risks define the “utility function”. Useful models are associated with high values of the utility function. Such methods are beyond the scope of this book, but we highly recommend focusing on the purpose of the model when comparing (or selecting) models. A primer to decision analysis can be found in Yokomizo et al. (2014).</p>
</div>
<div id="methods-for-model-commparison" class="section level2 hasAnchor" number="17.2">
<h2><span class="header-section-number">17.2</span> Methods for model commparison<a href="model_comparison.html#methods-for-model-commparison" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="cross-validation" class="section level3 hasAnchor" number="17.2.1">
<h3><span class="header-section-number">17.2.1</span> Cross-validation<a href="model_comparison.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The principle of cross-validation is to fit the model using only a part of the data (training data) and to make predictions based on the data that are held out. The differences between the observed and predicted values are measured. Frequentists use the mean squared differences (MSE) or the root of the MSE (RMSE) as a measure of predictive fit (cross-validation score). Bayesians sum the logarithm of the predictive density values of the hold-out data points using the model fitted to the training data (see following). To do a cross-validation, one observation at a time can be held out (leave-one-out cross-validation) or several observations can be held out simultaneously (<span class="math inline">\(k\)</span>-fold cross-validation, where <span class="math inline">\(k\)</span> is the number of groups held out in turn). How many observations should be held out in turn depends on the data structure. The holdout data should be independent of the training data (e.g., leave out an entire level of a random factor; the data held out should not be spatially or temporally correlated with the training data). In the case of unstructured (independent) data, each single observation is left out in turn. For hierarchical or grouped data (mixed models) the cross-validation procedure has to be programmed in R by hand, because the way the data are partitioned into training and holdout sets is unique to each data set.<br />
For independent observations (LM or GLM), the function <code>loo.cv</code> calculates the Bayesian leave-one-out cross-validation estimate of predictive fit (described in <span class="citation">A. Gelman et al. (<a href="referenzen.html#ref-Gelman.2014">2014</a>)</span>). It leaves out one observation <span class="math inline">\(y_i\)</span> at a time, and fits the model to the remaining data <span class="math inline">\(y_{-i}\)</span>. Then, it integrates the predictive density of <span class="math inline">\(y_i\)</span> over the posterior distribution of the model parameters. The log of this value is summed over all observations (i.e., leaving out each observation in turn) to return the leave-one-out cross-validation estimate of predictive fit. The larger this value is, the better the prediction fits the left-out observations.<br />
Because all <span class="math inline">\(n\)</span> models are based on <span class="math inline">\(n - 1\)</span> observations only, the predictive fit is underestimated, especially when sample size is small. This bias can be corrected by setting the argument “bias.corr” to TRUE.</p>
<!-- wäre schön, ein richtiges Beispiel zu verwenden, z.B. Christians Atlas-Daten?-->
<p>We illustrate Bayesian leave-one-out cross-validation using the “pondfrog1” data. This data set contains the size of frog populations in different ponds with different characteristics. It includes simulated data. Therefore, the “true” model is known and model comparison using different methods may be illustrative. Let’s say that we need to estimate the total frog population in a large area with around 5000 small ponds. It is not feasible to count the number of frogs in 5000 ponds. Therefore, we would like to predict the number of frogs for the 5000 ponds from a sample of 130 ponds, for which the frog populations have been counted, and pH, water depth, and average temperature have been measured. The aim is to use these variables as predictors for the number of frogs for the remaining 4870 ponds. Measuring water depth, pH, and temperature is expensive. Therefore, we would like to include only those
predictors that are really necessary.</p>
<p>For example, say it was well known that waterdepth and temperature are important factors determining how many frogs inhabit a pont. However we are unsure about ph. We need to decide whether we would like to consider ph as a predictor. First, we fit two models, one including ph and one excluding ph as predictor.</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="model_comparison.html#cb295-1" tabindex="-1"></a><span class="fu">data</span>(pondfrog1) <span class="co"># data in the package blmeco</span></span>
<span id="cb295-2"><a href="model_comparison.html#cb295-2" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(frog <span class="sc">~</span> waterdepth <span class="sc">+</span> temp <span class="sc">+</span> ph, <span class="at">data=</span> pondfrog1,</span>
<span id="cb295-3"><a href="model_comparison.html#cb295-3" tabindex="-1"></a><span class="at">family=</span>poisson)</span>
<span id="cb295-4"><a href="model_comparison.html#cb295-4" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(frog <span class="sc">~</span> waterdepth <span class="sc">+</span> temp, <span class="at">data=</span>pondfrog1,</span>
<span id="cb295-5"><a href="model_comparison.html#cb295-5" tabindex="-1"></a><span class="at">family=</span>poisson)</span></code></pre></div>
<p>The leave-one-out cross-validation predictive performance of the different models can be compared.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="model_comparison.html#cb296-1" tabindex="-1"></a>loo1 <span class="ot">&lt;-</span> <span class="fu">loo.cv</span>(mod1, <span class="at">bias.corr=</span><span class="cn">TRUE</span>) <span class="co"># increase nsim for more precise results</span></span>
<span id="cb296-2"><a href="model_comparison.html#cb296-2" tabindex="-1"></a>loo2 <span class="ot">&lt;-</span> <span class="fu">loo.cv</span>(mod2, <span class="at">bias.corr=</span><span class="cn">TRUE</span>)</span>
<span id="cb296-3"><a href="model_comparison.html#cb296-3" tabindex="-1"></a>loo1<span class="sc">$</span>bias.corrected.LOO.CV; loo2<span class="sc">$</span>bias.corrected.LOO.CV</span></code></pre></div>
<pre><code>## [1] -402.3158</code></pre>
<pre><code>## [1] -404.6208</code></pre>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="model_comparison.html#cb299-1" tabindex="-1"></a>loo1<span class="sc">$</span>est.peff; loo2<span class="sc">$</span>est.peff</span></code></pre></div>
<pre><code>## [1] 4.304329</code></pre>
<pre><code>## [1] 3.286246</code></pre>
<p>The output gives the leave-one-out cross-validation estimate of predictive fit. The bias-corrected leave-one-out cross-validation, which is recommended for small sample sizes. We also get an estimate for the number of effective parameters (est.peff), which is the difference between the non-cross-validated predictive fit and the cross-validated predictive fit (LOO.CV). It measures “overfit”, that is, how much the model fits better to the data used for model fitting compared to new data. The model without ph seems to have
the higher out-of data predictive fit.</p>
<p>Cross-validation in a Bayesian framework is extremely computing time intensive, because <span class="math inline">\(n\)</span> models have to be fitted, and for each model the posterior distribution of the parameter estimates needs to be simulated. Frequentist cross-validation requires less computing time, because no posterior distributions have to be simulated. And, for normal linear models, a leave-one-out cross-validation can be computed using matrix algebra without having to refit any model <span class="citation">(e.g., see <a href="referenzen.html#ref-Wood.2017">S. Wood 2017</a>)</span>. This may be a fast alternative.</p>
</div>
<div id="information-criteria-akaike-information-criterion-and-widely-applicable-information-criterion" class="section level3 hasAnchor" number="17.2.2">
<h3><span class="header-section-number">17.2.2</span> Information criteria: Akaike information criterion and widely applicable information criterion<a href="model_comparison.html#information-criteria-akaike-information-criterion-and-widely-applicable-information-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Akaike information criterion (AIC) and the widely applicable information criterion (WAIC) are asymptotically equivalent to cross-validation <span class="citation">(<a href="referenzen.html#ref-Stone.1977">Stone 1977</a>; <a href="referenzen.html#ref-Gelman.2014">A. Gelman et al. 2014</a>)</span>. AIC is minus two times the log likelihood (the “frequentist” likelihood, Chapter <a href="bayesian_paradigm.html#likelihood">9.3</a>) plus two times the number of model parameters <span class="citation">(<a href="referenzen.html#ref-Akaike.1974">Akaike 1974</a>)</span>:
<span class="math display">\[AIC = -2log(L(\widehat{\theta^{ML}}|y)) + 2K = -2log(p(y|\widehat{\theta^{ML}}))\]</span>
where <span class="math inline">\(\widehat{\theta^{ML}}\)</span> is the vector of maximum likelihood estimates of the model parameters and <span class="math inline">\(K\)</span> is the number of parameters.</p>
<p>The first quantity measures the model fit. Because of the factor “-2”, the smaller the value, the better the model fits the data. The second quantity penalizes for overfit: for each parameter, a value of two is added. Generally, the smaller the AIC, the “better” is the predictive performance of the model.
Philosophically, AIC is an estimate of the expected relative distance between the fitted model and the unknown true mechanism that actually generated the observed data <span class="citation">(<a href="referenzen.html#ref-Burnham.2002">Burnham and White 2002</a>)</span>.</p>
<p>When sample size is small, a higher penalty term is needed and a corrected AIC value is more reliable:
<span class="math display">\[ AIC_c = AIC + 2 \frac{K(K+1)}{n-K-1}\]</span>
As <span class="math inline">\(AIC_c\)</span> approximates <span class="math inline">\(AIC\)</span> for large samples, it is recommended to us <span class="math inline">\(AICc\)</span> in all cases.</p>
<p>The <span class="math inline">\(AIC\)</span> can be used to rank models similar to the cross-validation estimate of predictive fit. Different models can be weighted according to their <span class="math inline">\(AIC\)</span> values and <span class="math inline">\(AIC\)</span> weights are used to obtain an averaged model, or averaged derived parameters. Because <span class="math inline">\(AIC\)</span> is based on point estimates of the model parameters rather than their posterior distribution, the <span class="math inline">\(WAIC\)</span> is preferred by Bayesians. Further, <span class="math inline">\(AIC\)</span> does not work in cases with informative prior distributions and for hierarchical models <span class="citation">(<span class="math inline">\(AIC\)</span>-variants have been proposed for hierarchical models; <a href="referenzen.html#ref-Burnham.2002">Burnham and White 2002</a>; <a href="referenzen.html#ref-Vaida.2005">Vaida and Blanchard 2005</a>)</span>. AIC weights correspond to Bayesian posterior model probabilities given specific prior model probabilities <span class="citation">(<a href="referenzen.html#ref-Anderson.2008">D. R. Anderson 2008</a>)</span>.</p>
<p>The WAIC is a Bayesian version of the AIC. It behaves asymptotically similar to the Bayesian cross-validation <span class="citation">(<a href="referenzen.html#ref-Watanabe.2010">Watanabe 2010</a>)</span>. It also works for hierarchical models and when informative priors are used. Its formula looks similar to the one for the AIC, but instead of the log-likelihood for the ML-point estimates of the model parameters, WAIC uses the logarithm of the pointwise predictive density (the likelihood function averaged over the posterior distribution of the model parameters and its logarithm summed over all observations<!-- fk: füge Referenz zu Likelihood chapter -->). The penalization term for overfit is an estimate of the number of effective parameters.</p>
<p><span class="math display">\[ WAIC = -2log(p(y|\theta_{post})) + 2p_{WAIC}\]</span>
where <span class="math inline">\(\theta_{post}\)</span> is the joint posterior distribution of the model parameters and <span class="math inline">\(p_{WAIC}\)</span> an estimate of the number of effective parameters. <span class="math inline">\(p_{WAIC}\)</span> can be calculated in two different ways, therefore, two different <span class="math inline">\(WAIC\)</span> values exist <span class="citation">(<a href="referenzen.html#ref-Gelman.2014">A. Gelman et al. 2014</a>)</span>. Both are implemented in the function <code>WAIC</code> (from the package <code>blmeco</code>) but the WAIC2 more strongly resembles the cross-validation and is, therefore, recommended.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="model_comparison.html#cb302-1" tabindex="-1"></a><span class="fu">WAIC</span>(mod1, <span class="at">nsim=</span><span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## $lppd
## [1] -397.9595
## 
## $pwaic1
## [1] 4.263306
## 
## $pwaic2
## [1] 4.666476
## 
## $WAIC1
## [1] 804.4456
## 
## $WAIC2
## [1] 805.2519</code></pre>
<p>The <code>lppd</code> is the log pointwise posterior predictive density (a measure of fit; the better the model fits the data the larger it is). <code>pwaic1</code> and <code>pwaic2</code> are the two estimates for the effective number of parameters, a measure for the increase in model fit that is solely due to the number of parameters, and that is used to estimate WAIC1 and WAIC2. The WAIC2 values for the second model in our frog example was 809.4. Thus the conclusion is similar as with the cross-validation.<br />
A technical warning: To compare models, the models must have been fitted using the same data set. R omits observations with missing values when fitting a linear model! Thus, if a predictor variable contains missing values, R fits the model to data excluding the missing cases. We only see this in a small note in the summary output, which is easily overlooked. When excluding the predictor variable with missing values from the model, R fits the model to a larger data set. As a result, the two models cannot be compared because they have been fitted to different data. Therefore, we have to make sure that all models we compare have been fitted to the same data set. Such a line of code may prevent unjustified comparisons:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="model_comparison.html#cb304-1" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> dat[<span class="fu">complete.cases</span>(dat),]</span></code></pre></div>
<p>where “dat” contains the outcome variable and all predictors (but no other variables with NAs, or too many cases might be deleted).<br />
We are not aware of anyone who has used WAIC weights in a way similar to AIC weights. This may be because WAIC is quite new or because, in a Bayesian framework, posterior model probabilities are available. These probabilities quantify, based on probability theory, the probability that a model is the “true” (or, better, “the most realistic”) model given a set of models, the data, and the prior model probabilities.</p>
</div>
<div id="other-information-criteria" class="section level3 hasAnchor" number="17.2.3">
<h3><span class="header-section-number">17.2.3</span> Other information criteria<a href="model_comparison.html#other-information-criteria" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Bayesian information criterion (BIC) was introduced by <span class="citation">Schwarz (<a href="referenzen.html#ref-Schwarz.1978">1978</a>)</span> and discussed by <span class="citation">Hoeting et al. (<a href="referenzen.html#ref-Hoeting.1999">1999</a>)</span>. Its purpose is not to measure the predictive performance of a model, but to obtain posterior model probabilities. The results obtained by BIC approximate results obtained by Bayes factors given specific conditions (e.g., see <span class="citation">Link and Barker (<a href="referenzen.html#ref-Link.2010">2010</a>)</span>). It is no longer considered to be a Bayesian method <span class="citation">(<a href="referenzen.html#ref-Gelman.1995">A. Gelman and Rubin 1995</a>)</span>. It differs from the AIC only in the penalization term that takes sample size into account.</p>
<p><span class="math display">\[ BIC = -2log(p(y|\hat{\theta^{ML}}))+log(n)K\]</span>
Even though it is similar to <span class="math inline">\(AIC\)</span>, its purpose is different. The assumptions made by <span class="math inline">\(BIC\)</span>, particularly concerning the prior model probabilities, are so specific that in many cases it may not do what we expect. Thus, constructing Bayes factors using specific prior model probabilities may be preferred.</p>
<p>The deviance information criterion <span class="math inline">\(DIC\)</span> <span class="citation">(<a href="referenzen.html#ref-Spiegelhalter.2002">Spiegelhalter et al. 2002</a>)</span> corresponds to the <span class="math inline">\(AIC\)</span> for models fitted in a Bayesian framework. However, unlike the <span class="math inline">\(WAIC\)</span>, it conditions on the point estimates of the model parameters <span class="math inline">\(\bar\theta\)</span> rather than averages over their posterior distribution. It is
<span class="math display">\[ DIC = -2log(p(y|\bar\theta))+2p_D\]</span>
where <span class="math inline">\(p_D\)</span> is the effective number of parameters. The first term is the deviance calculated for the mean of the posterior distribution. The effective number of parameters is the difference between the posterior mean deviance and the deviance of the mean parameters. The smaller the <span class="math inline">\(DIC\)</span>, the higher the predictive performance of the model. For some hierarchical models <span class="math inline">\(DIC\)</span> does not seem to behave reliably (e.g., Millar, 2009)<!-- fk: search for reference!-->.</p>
</div>
<div id="bayes-factors-and-posterior-model-probabilities" class="section level3 hasAnchor" number="17.2.4">
<h3><span class="header-section-number">17.2.4</span> Bayes factors and posterior model probabilities<a href="model_comparison.html#bayes-factors-and-posterior-model-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Bayes factor corresponds to the likelihood ratio, but instead of evaluating the likelihood function for the ML-estimates, the likelihood function is integrated over the posterior distribution of the model parameters. The Bayes factor is useful when choosing one model over another when these models represent discrete, mutually exclusive hypotheses. This is a very rare situation. Furthermore, based on Bayes factors, posterior model probabilities for each model in a set of models can be calculated. Such posterior model probabilities are useful because they reflect the support in the data for each model.
Unfortunately, Bayes factors and the posterior model probabilities are very sensitive to the specification of prior model probabilities, and even to the specification of prior distributions for the model parameters. Therefore, we recommend applying Bayes factors only with informative priors. Applying Bayes factors requires some experience with prior distributions; an introduction to Bayes factors is given in, for example, <span class="citation">Link and Barker (<a href="referenzen.html#ref-Link.2010">2010</a>)</span> or <span class="citation">A. Gelman et al. (<a href="referenzen.html#ref-Gelman.2014">2014</a>)</span>. In the next chapter, we introduce the R package BMS, which allows calculation of posterior model probabilities. There, we also show that the specification of the prior distributions for the model coefficients and the models is essential.</p>
</div>
<div id="model-based-methods-to-obtain-posterior-model-probabilities-and-inclusion-probabilities" class="section level3 hasAnchor" number="17.2.5">
<h3><span class="header-section-number">17.2.5</span> Model-based methods to obtain posterior model probabilities and inclusion probabilities<a href="model_comparison.html#model-based-methods-to-obtain-posterior-model-probabilities-and-inclusion-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Model-based selection methods include the process of model selection in the model fitting process. Many techniques exist to do model-based model selection. <span class="citation">O’Hara and Sillanpää (<a href="referenzen.html#ref-OHara.2009">2009</a>)</span> and <span class="citation">Hooten and Hobbs (<a href="referenzen.html#ref-Hooten.2015">2015</a>)</span> review a number of these techniques. In the next section, we introduce the least absolute shrinkage and selection operator (LASSO) and ridge regression. Here, we briefly introduce reversible jump Markov chain Monte Carlo simulation (RJMCMC), an indicator variable selection to obtain inclusion probabilities and posterior model probabilities.
RJMCMC is a simulation technique that allows sampling from the posterior distribution of the model parameters of different models simultaneously. The simulation algorithm jumps between the different models in such a way that the number of “visits” it spends at the different models is proportional to their posterior model probabilities. Model averaging <!-- fk: insert link--> can be done based on such simulations. The posterior inclusion probability is the posterior probability that a specific variable is included in the model given the prior distributions for the parameters, the set of models, and the data. These probabilities correspond to the proportion of RJMCMC iterations from the models with the specific variable. The software WinBUGS provides RJMCMC for linear regression type models (see e.g., <span class="citation">Gimenez et al. (<a href="referenzen.html#ref-Gimenez.2009">2009</a>)</span>). For other types of models, RJMCMC algorithms have to be programmed in R or another programming language (e.g., see <span class="citation">King and Brooks (<a href="referenzen.html#ref-King.2002">2002</a>)</span>; <span class="citation">Gimenez et al. (<a href="referenzen.html#ref-Gimenez.2009">2009</a>)</span>).</p>
<p>Another method to obtain predictor inclusion probabilities is to multiply each parameter in the model by a latent (unobserved) indicator variable. This latent indicator variable is assumed to be Bernoulli distributed. The parameter of the Bernoulli distribution corresponds to the inclusion probability and can be estimated in addition to the parameter values. This method has been called “indicator variable selection”. Because such models contain a lot of parameters, informative prior information for the model parameters helps to obtain a reliable model fit (e.g., <span class="citation">Carlin and Chib (<a href="referenzen.html#ref-Carlin.1995">1995</a>)</span>; BUGS code is presented in the supplementary material of <span class="citation">O’Hara and Sillanpää (<a href="referenzen.html#ref-OHara.2009">2009</a>)</span> or <span class="citation">J. A. Royle (<a href="referenzen.html#ref-Royle.2009">2009</a>)</span>).</p>
</div>
<div id="least-absolute-shrinkage-and-selection-operator-lasso-and-ridge-regression" class="section level3 hasAnchor" number="17.2.6">
<h3><span class="header-section-number">17.2.6</span> Least absolute shrinkage and selection operator (LASSO) and ridge regression<a href="model_comparison.html#least-absolute-shrinkage-and-selection-operator-lasso-and-ridge-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section, we introduce two model-based methods that can be used to reduce the model dimension (i.e., the number of parameters): the LASSO (least absolute shrinkage and selection operator; <span class="citation">Tibshirani (<a href="referenzen.html#ref-Tibshirani.1996">1996</a>)</span>) and ridge regression. The principle of these methods is to constrain the model coefficients within the model, so that some of them either shrink toward zero or become zero. This reduces the model dimensions because explanatory variables whose coefficients become zero are “omitted” from the model. An advantage of these methods compared to information criteria such as WAIC is that the data analyst can choose the degree of dimension reduction.</p>
<p>To illustrate, we apply LASSO to a multiple regression with the logarithm of the number of frogs as the outcome variable and pH, temperature, and water depth as numeric predictors (data “pondfrog1”):
<span class="math display">\[ y_i \sim normal(\mu_i, \sigma_i) \]</span>
<span class="math display">\[\mu_i = \beta_0 + \beta_1pH_i + \beta_2waterdepth_i + \beta_3temperature_i \]</span>
Amphibian specialists would leave all three variables in the model because they know that these variables are important limiting factors for amphibians. However, to illustrate LASSO, let’s imagine for the moment that we had no idea about which of these variables are important (and we could have over 100 such variables!). To filter out the important variables, we add the constraint that the sum of the absolute values for the slope parameters does not exceed a specific value. The mathematical notation for this constraint is:
<span class="math display">\[ \sum_{i=1}^3 |\beta_i| \leq t\]</span>
As a result, depending on <span class="math inline">\(t\)</span>, some of the coefficients collapse to zero. Note that we do not add any constraint for the intercept. Also, it is important that all variables, including the outcome variable, are z-transformed so that the scale of all variables is the same. The R package <code>lasso2</code> provides functions to fit LASSO in a frequentist framework. The Bayesian LASSO is constructed by specifying a Laplace distribution as a prior distribution for the model coefficients <span class="math inline">\(\beta_i\)</span> instead of having independent prior distributions for each bi (e.g., see <span class="citation">Hooten and Hobbs (<a href="referenzen.html#ref-Hooten.2015">2015</a>)</span>). Bayesian LASSO models can be fitted in BUGS or Stan (<span class="citation">O’Hara and Sillanpää (<a href="referenzen.html#ref-OHara.2009">2009</a>)</span>).</p>
<!-- fk: add a lasso example in a Bayesian framework-->
<p>Ridge regression is similar to LASSO. The difference is the form of the constraint. Instead of constraining the sum of the absolute values of the model coefficients, the sum of the squared model coefficients is constraint:</p>
<p><span class="math display">\[ \sum_{i=1}^3 \beta_i^2 \leq t\]</span></p>
<p>In ridge regression, model coefficients do not become exactly zero but they are shrunk toward zero. Thus, the coefficients of “unimportant” predictors will be closer to zero than when they are estimated without the constraint (i.e., simply using <code>lm</code>). The Bayesian equivalent to ridge regression is to specify a prior distribution for the <span class="math inline">\(\beta_i\)</span>, for example, <span class="math inline">\(\beta_i \sim normal(0, \sigma_i)\)</span>. The priors for <span class="math inline">\(\sigma_i\)</span> then specify how strongly the parameter estimates are shrunk toward zero. Different types of prior distributions for the coefficients and for <span class="math inline">\(\sigma_i\)</span> have been used; see, for example, <span class="citation">Brown, Vannucci, and Fearn (<a href="referenzen.html#ref-Brown.2002">2002</a>)</span>, <span class="citation">MacLehose et al. (<a href="referenzen.html#ref-MacLehose.2007">2007</a>)</span>, or <span class="citation">Armagan and Zaretzki (<a href="referenzen.html#ref-Armagan.2010">2010</a>)</span>.<br />
LASSO and ridge regression can handle situations with more predictor variables than observations. Such data sets are common in genetics, for example, when the expression of &gt;10,000 genes is measured in a sample of <span class="math inline">\(n\)</span> individuals with <span class="math inline">\(n\)</span> typically much smaller than 10,000, and the aim is to pinpoint the genes whose expressions correlate with specific phenotypes of the individuals. Another advantage of LASSO and ridge regression is that the degree of the constraint can be chosen in relation to what the model is used for, that is, in a decision theoretic framework (e.g., <span class="citation">Brown, Vannucci, and Fearn (<a href="referenzen.html#ref-Brown.2002">2002</a>)</span>; <span class="citation">Wan (<a href="referenzen.html#ref-Wan.2002">2002</a>)</span>).</p>
</div>
</div>
<div id="multimodel-inference" class="section level2 hasAnchor" number="17.3">
<h2><span class="header-section-number">17.3</span> Multimodel inference<a href="model_comparison.html#multimodel-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Multimodel inference is the process of drawing inference while taking model selection uncertainty into account. The principle is to average the model parameters over all (or at least several) possible models weighted by model probabilities. Often, people have used <span class="math inline">\(AIC\)</span> weights <span class="citation">(<a href="referenzen.html#ref-Burnham.2002">Burnham and White 2002</a>)</span>. Here, we show how to do model averaging in R based on posterior model probabilities using the R package <code>BMS</code> <span class="citation">(<a href="referenzen.html#ref-Zeugner.2011">Zeugner 2011</a>)</span>. But the R code given in the following also works when the posterior model probabilities are replaced with <span class="math inline">\(AIC\)</span> weights if these are preferred.<br />
Bayesian multimodel inference provides much flexibility in how to weigh different aspects of the model via the priors. The priors for the model parameters and the model probabilities strongly influence posterior model probabilities often in not so easily understandable ways. For example, when we use flat priors for all parameters, we would expect that larger models would get higher posterior model probabilities. However, this can interfere with the prior for the model probabilities, when we specify these to favor smaller models and vice versa. Here, it is not possible to give a comprehensive overview of all the possible priors and their usage. We only give a simple example to communicate the principles of Bayesian multimodel inference. To start using Bayesian multimodel inference, we recommend <span class="citation">Hoeting et al. (<a href="referenzen.html#ref-Hoeting.1999">1999</a>)</span> as well as the tutorials and the online material for the <code>BMS</code> package <span class="citation">(<a href="referenzen.html#ref-Zeugner.2011">Zeugner 2011</a>)</span>.<br />
Model averaging yields averaged parameter estimates, but it is also possible to obtain averaged model predictions, or averaged estimates for any other derived parameter, with credible intervals.</p>
<p>In the following, we show how to obtain averaged model predictions with credible intervals according to the methods described in <span class="citation">Hoeting et al. (<a href="referenzen.html#ref-Hoeting.1999">1999</a>)</span> using the package <code>BMS</code> and the function <code>sim</code>. We again use the pond frog example.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="model_comparison.html#cb305-1" tabindex="-1"></a><span class="fu">library</span>(BMS)</span></code></pre></div>
<p>First, create the data matrix with the dependent variable in the first column and all other columns containing numeric values of the predictors; factors, if present, need to be transformed to dummy variables.</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="model_comparison.html#cb306-1" tabindex="-1"></a>pondfrog1<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">log</span>(pondfrog1<span class="sc">$</span>frog<span class="sc">+</span><span class="dv">1</span>) <span class="co"># transform for reaching better the normal distribution</span></span>
<span id="cb306-2"><a href="model_comparison.html#cb306-2" tabindex="-1"></a>X <span class="ot">&lt;-</span> pondfrog1[, <span class="fu">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;ph&quot;</span>, <span class="st">&quot;waterdepth&quot;</span>, <span class="st">&quot;temp&quot;</span>)]</span></code></pre></div>
<p>Before we start doing multimodel inference using the function <code>bms</code>, we need to specify priors for the model coefficients and for the model probabilities. The priors for the model probabilities are given in the argument mprior. “uniform” means uniform prior probabilities for all models <span class="math inline">\(M_i\)</span>, <span class="math inline">\(p(M_i) \propto 1\)</span> (a horizontal line at 1, which is an improper prior, see <a href="priors.html#priors">Chapter on priors</a>). For the intercept and the residual variance, the function <code>bms</code> also uses improper priors, that is, <span class="math inline">\(\propto 1\)</span> for the intercept and <span class="math inline">\(\proto 1/\sigma\)</span> for the residual standard deviation.
For the model coefficients, the function <code>bms</code> uses the so-called Zellner’s g prior, which is defined by the parameter <span class="math inline">\(g\)</span>. It describes a multivariate normal distribution for the coefficients, with expected values of zero for all coefficients and a variance-covariance structure defined by the variance in the data and the parameter <span class="math inline">\(g\)</span>. The larger <span class="math inline">\(g\)</span> is, the less certain the researcher is that the coefficients are zero. A Zellner’s g prior results in t-distributions for the posterior distributions for the coefficients with means equal to <span class="math inline">\(g/(1 - g) \hat{\beta^{LS}}\)</span>, where <span class="math inline">\(\hat{\beta^{LS}}\)</span> is the ordinary least-squares estimate that we would obtain using <code>lm</code>. The default “UIP” (unit information prior) sets <span class="math inline">\(g = n\)</span> (sample size). Using <span class="math inline">\(g = n\)</span> and uniform priors for the model probabilities leads to asymptotically equal results as when using <span class="math inline">\(BIC\)</span>.<br />
The function <code>bms</code> fits all possible models and calculates posterior inclusion probabilities (PIP) of each variable as well as the posterior means and standard deviations of the model-averaged parameters.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="model_comparison.html#cb307-1" tabindex="-1"></a>bmsmod <span class="ot">&lt;-</span> <span class="fu">bms</span>(X, <span class="at">mprior=</span><span class="st">&quot;uniform&quot;</span>, <span class="at">g=</span><span class="st">&quot;UIP&quot;</span>)</span></code></pre></div>
<pre><code>##                  PIP    Post Mean     Post SD Cond.Pos.Sign Idx
## waterdepth 1.0000000 -0.302381905 0.010771244             0   2
## temp       1.0000000  0.191626285 0.003888324             1   3
## ph         0.1290152  0.006211641 0.023388692             1   1
## 
## Mean no. regressors               Draws             Burnins                Time 
##            &quot;2.1290&quot;                 &quot;8&quot;                 &quot;0&quot;  &quot;0.005306959 secs&quot; 
##  No. models visited      Modelspace 2^K           % visited         % Topmodels 
##                 &quot;8&quot;                 &quot;8&quot;               &quot;100&quot;               &quot;100&quot; 
##            Corr PMP            No. Obs.         Model Prior             g-Prior 
##                &quot;NA&quot;               &quot;130&quot;     &quot;uniform / 1.5&quot;               &quot;UIP&quot; 
##     Shrinkage-Stats 
##         &quot;Av=0.9924&quot; 
## 
## Time difference of 0.005306959 secs</code></pre>
<p><img src="2.09-model_comparison_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The variables in the output are ordered according to their PIP. The (according to the inclusion probabilities) most important variables come first. The second column gives the posterior means of the parameters averaged over the models. It corresponds to a weighted mean of the estimates from the models with the model probabilities as weights. By default, the posterior mean is calculated over all models using the value 0 for models excluding the variable (unconditional posterior mean).</p>
<p>By setting the argument <code>condi.coef = TRUE</code>, only the models including a variable are used to calculate the posterior mean. The column Post SD is the posterior standard deviation of the parameter estimates. The next column gives the posterior probability that the parameter value is positive conditional on the inclusion of this parameter. Thus, we can infer from the output that water depth and temperature are important predictors (inclusion probabilities close to 1), and that water depth has a negative and temperature a positive effect on the size of the frog population in a pond.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="model_comparison.html#cb309-1" tabindex="-1"></a><span class="co">#fk: for some reasons, this does no longer work well</span></span>
<span id="cb309-2"><a href="model_comparison.html#cb309-2" tabindex="-1"></a><span class="fu">topmodels.bma</span>(bmsmod)[,<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>] <span class="co"># we extract only the 5 &quot;best&quot; models</span></span></code></pre></div>
<pre><code>##                        3            7            1            5        2
## ph          0.000000e+00 1.000000e+00 0.000000e+00 1.000000e+00    0.000
## waterdepth  1.000000e+00 1.000000e+00 0.000000e+00 0.000000e+00    1.000
## temp        1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00    0.000
## PMP (Exact) 8.085053e+86 1.197603e+86 4.529691e+32 4.302559e+31 7889.719
## PMP (MCMC)  8.085053e+86 1.197603e+86 4.529691e+32 4.302559e+31 7889.719</code></pre>
<p>The posterior model probabilities are nearly zero, which is completely different from what the same R-code produced when we used it 10 years ago. We have to find out what changed, and then will revise this chapter.</p>
<p>Another remark we would like to add: It has been questioned whether it makes sense to assign the hypothesis <span class="math inline">\(H: \beta = 0\)</span> a positive value (e.g., <span class="citation">A. Gelman et al. (<a href="referenzen.html#ref-Gelman.2014">2014</a>)</span>), because the probability that a continuous parameter is exactly 0 is always 0. This is at odds with the notion of posterior inclusion probabilities lower than 1. For this reason, it may be preferable to use a model that shrinks the coefficients toward 0 (rather than excluding predictors), such as in ridge regression.</p>
</div>
<div id="which-method-to-choose-and-which-strategy-to-follow" class="section level2 hasAnchor" number="17.4">
<h2><span class="header-section-number">17.4</span> Which method to choose and which strategy to follow?<a href="model_comparison.html#which-method-to-choose-and-which-strategy-to-follow" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As outlined in the first section of this chapter, before starting model selection and multimodel inference a few questions should be asked: What is the type of the study? Maybe the model is defined by the study design and a formal model selection method is not needed or may even be harmful because model selection increases bias. Is the sample size large compared to the number of model parameters? If yes, a formal model selection process may also not be necessary because precision is sufficiently high to draw conclusions from the model. If sample size is low, formal model selection may be important to extract the relevant information in the data. What is the aim of a study? For a basic research study that aims to understand the system, we may be more reluctant to apply a formal model selection method, because unbiased estimates of the effects are important. In contrast, if the study has an applied purpose, formal model selection, particularly in combination with decision theoretic approaches, can strongly increase the usefulness of a model.</p>
<!-- fk: Unten habe ich notdürftig eingesetzt, Beschreibung der Abbildung fehlt und Abbildung soll neu gemacht werden!-->
<p>A parsimonious model does not necessarily perform best in all situations. On one hand, if important factors have to be ignored in a model just because of parsimony, the parameter estimates can be biased. Therefore, it may be better to include more parameters and accept that the uncertainty is increased (Gelman &amp; Rubin, 1995; Forstmeier &amp; Schielzeth, 2011). On the other hand, if we would like to extract the information inherent in the data (i.e., identify factors that are important based on the information in the data), we may go for the most parsimonious model and admit that we cannot say anything about the factors deleted from the model, and that estimated effect sizes of the remaining factors may have some bias, that is, they may be less reliable (Burnham &amp; Anderson, 2002; Anderson, 2008).</p>
</div>
<div id="further-reading-6" class="section level2 hasAnchor" number="17.5">
<h2><span class="header-section-number">17.5</span> Further reading<a href="model_comparison.html#further-reading-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- fk: further reading im alten Buch ist sehr nützlich, sollte hier noch eingefügt werden-->
<!-- pk: hab ich gemacht; tredennick noch mit Text ergänzen?-->
<!-- pk: das gibt es nicht mehr: More information on the computation of LASSO and ridge regression is found at http://staffhome.ecm.uwa.edu.au/~00043886/software/lasso.html.-->
<p><span class="citation">Tredennick et al. (<a href="referenzen.html#ref-Tredennick.2021">2021</a>)</span></p>
<p><span class="citation">Kadane and Lazar (<a href="referenzen.html#ref-Kadane.2004">2004</a>)</span> discuss various versions of the Bayes factor and many more possibilities for Bayesian model selection. We can highly recommend the up-to-date review of the commonly used model selection methods in Bayesian statistics by <span class="citation">Hooten and Hobbs (<a href="referenzen.html#ref-Hooten.2015">2015</a>)</span>. They nicely explain the common framework of the information criteria, cross-validation, LASSO, and ridge regression, which is called regularization.</p>
<p><span class="citation">Wasserman (<a href="referenzen.html#ref-Wasserman.2000">2000</a>)</span> reviews AIC, BIC, and Bayes factor in a Bayesian framework. He also reviews model averaging. <span class="citation">A. Gelman and Rubin (<a href="referenzen.html#ref-Gelman.1995">1995</a>)</span> describe that BIC is not a Bayesian method, explain why Bayes factors are only defined when prior distributions are proper, and how Bayes factors are sensitive to prior distributions.</p>
<p>More details on multimodel inference in a Bayesian framework are provided in <span class="citation">Link and Barker (<a href="referenzen.html#ref-Link.2010">2010</a>)</span>. <span class="citation">Hoeting et al. (<a href="referenzen.html#ref-Hoeting.1999">1999</a>)</span> give a detailed description on how to do Bayesian model averaging.</p>
<p>The classical reference for information theory is <span class="citation">Burnham and White (<a href="referenzen.html#ref-Burnham.2002">2002</a>)</span>. <span class="citation">D. R. Anderson (<a href="referenzen.html#ref-Anderson.2008">2008</a>)</span> is a more digested version for practitioners, particularly ecologists. <span class="citation">Buckland, Burnham, and Augustin (<a href="referenzen.html#ref-Buckland.1997">1997</a>)</span> present model averaging as a tool to draw inference while taking model selection uncertainty into account.</p>
<p><span class="citation">Claeskens and Hjort (<a href="referenzen.html#ref-Claeskens.2008">2008</a>)</span> give a mathematical introduction to a variety of different information criteria and model selection techniques. <span class="citation">Johnson and Omland (<a href="referenzen.html#ref-Johnson.2004b">2004</a>)</span> review model selection in ecology and evolution and present advantages of model averaging. <span class="citation">Claeskens and Hjort (<a href="referenzen.html#ref-Claeskens.2003">2003</a>)</span> developed a focused information criteria, FIC, that aims at optimizing model selection in relation to one parameter of interest.</p>
<p><span class="citation">Grueber, Nakagawa, and Jamieson (<a href="referenzen.html#ref-Grueber.2011">2011</a>)</span> show how to do model averaging based on AIC weights for linear models including generalized linear mixed models. They also give R code in a worked example using the R package MuMIn (<span class="citation">Bartoń (<a href="referenzen.html#ref-Barton.2011">2011</a>)</span>). But note that the way <span class="citation">Grueber, Nakagawa, and Jamieson (<a href="referenzen.html#ref-Grueber.2011">2011</a>)</span> obtain the confidence intervals for the averaged fitted values is wrong, see corrigendum <span class="citation">Grueber et al. (<a href="referenzen.html#ref-Grueber.2011b">2011</a>)</span>.</p>
<p>The package AICcmodavg <span class="citation">(<a href="referenzen.html#ref-Mazerolle.2014">Mazerolle 2025</a>)</span> provides R functions to do multimodel inference on a variety of different model types. Different strategies to select models among a large number of models are discussed by <span class="citation">Ripley (<a href="referenzen.html#ref-Ripley.2004b">2004</a>)</span>.</p>
<p>A generalization of the ordinary cross-validation is used to find the smoothing parameters in additive models <span class="citation">(<a href="referenzen.html#ref-Wood.2006">S. N. Wood 2006</a>)</span>.</p>
<p><span class="citation">Arnold (<a href="referenzen.html#ref-Arnold.2009">2009</a>)</span> shows that the AIC can decrease when unimportant (random) variables are added to a model (“pretending variable problem”). <span class="citation">Whittingham et al. (<a href="referenzen.html#ref-Whittingham.2006">2006</a>)</span> show that stepwise backward model selection leads to overestimated effect sizes.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelchecking.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stan.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/TobiasRoth/BDAEcology/edit/master/2.09-model_comparison.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
