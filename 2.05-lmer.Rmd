
# Linear Mixed Effect Models{#lmer}


```{r fig.align='center', echo=FALSE, fig.link=''}
knitr::include_graphics('images/himmelsherold.jpg', dpi = 150)
```

------


## Background

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(arm)
library(blmeco)
```


### Why Mixed Effects Models?

Mixed effects models (or hierarchical models; see @Gelman.2007 for a discussion on the terminology) are used to analyze nonindependent, grouped, or hierarchical data. For example, when we measure growth rates of nestlings in different nests by taking mass measurements of each nestling several times during the nestling phase, the measurements are grouped within nestlings (because there are repeated measurements of each) and the nestlings are grouped within nests. Measurements from the same individual are likely to be more similar than measurements from different individuals, and individuals from the same nest are likely to be more similar than nestlings from different nests. Measurements of the same group (here, the “groups” are individuals or nests) are not independent. If the grouping structure of the data is ignored in the model, the residuals do not fulfill the independence assumption.  

Further, predictor variables can be measured on different hierarchical levels. For example, in each nest some nestlings were treated with a hormone implant whereas others received a placebo. Thus, the treatment is measured at the level of the individual, while clutch size is measured at the level of the nest. Clutch size was measured only once per nest but entered in the data file more than once (namely for each individual from the same nest). Repeated measure results in pseudoreplication if we do not account for the hierarchical data structure in the model. Mixed models allow modeling of the hierarchical structure of the data and, therefore, account for pseudoreplication.  

Mixed models are further used to analyze variance components. For example, when the nestlings were cross-fostered so that they were not raised by their genetic parents, we would like to estimate the proportions of the variance (in a measurement, e.g., wing length) that can be assigned to genetic versus to environmental differences.  

The three problems - grouped data, repeated measure and interest in variances - are solved by adding further variance parameters to the model. As a result, the linear predictor of such models contains predictors with fixed parameters and predictors with non-fixed  parameters. The former are called "fixed effects", the latter "random effects". "Fixed effects" can be a slope (for a continuous predictor), or a defined set of levels for a factor (often called a "fixed factor"). The non-mixed models presented in Chapter \@ref(lm) (and later in Chapter \@ref(glm)) only have such "fixed effects". A mixed model, on the other hand, contains fixed and random effects. Typically, a grouping variable as described above is treated as a "random factor". "Random factor" is a somewhat misleading name as it is not the factor that is random. Rather, the levels of the factor are seen as a random sample from a bigger population of levels (e.g. nests), and  we assume that the level-specific parameter value comes from a distribution, usually the normal distribution. Thus, a random effect in a model can be seen as a model (for a parameter) that is nested within the model for the data.

Predictors that are defined as fixed effects are either numeric or, if they are categorical, they have a finite (“fixed”) number of levels, defined by the research question. For example, the factor “treatment” in the Barn owl study below has exactly two levels: "placebo" and "corticosterone", and nothing more. In contrast, random effects have a theoretically infinite number of levels of which we have measured a random sample. For example, we have measured 10 nests, but there are many more nests in the world that we have not measured. Normally, fixed effects have a low number of levels whereas random effects have a large number of levels (at least 3!). For fixed effects we are interested in the specific differences between levels (e.g., between males and females, placebo and corticosterone, etc), whereas for random effects we are mainly interested in the between-level (between-group, e.g., between-nest) variance rather than in differences between specific levels (e.g., nest A versus nest B).
Typical fixed effects are: treatment, sex, age classes, or season. Typical random effects are: nest, individual, field, school, or study plot. It depends sometimes on the aim of the study whether a factor should be treated as fixed or random. When we would like to compare the average size of a corn cob between specific regions, then we include region as a fixed factor. However, when we would like to know how the size of a corn cob is related to the irrigation system and we have several measurements within each of a sample of regions, then we treat region as a random factor.


### Random Factors and Partial Pooling

In a model with fixed factors, the differences of the group means to the mean of the reference group are separately estimated as model parameters. This produces $k-1$ (independent) model parameters, where $k$ is the number of groups (or number of factor levels). In contrast, for a random factor, the between-group variance is estimated and the $k$ group-specific means are assumed to be normally distributed around the population mean. These $k$ means are thus not independent. We usually call the differences between the specific mean of group $g$ and the mean of all groups $b_g$ (one value per group). They are assumed to be realizations of the same (in most cases normal) distribution with a mean of zero. They are like residuals. The variance of the $b_g$ values is the among-group variance. 

Treating a factor as a random factor is equivalent to "partial pooling" of the data. There are three different ways to obtain means for grouped data. First, the grouping structure of the data can be ignored - we simply estimate a mean across all data. This is called complete pooling (left panel in Figure \@ref(fig:pooling)).  

Second, group means may be estimated separately for each group. In this case, the data from all other groups are ignored when estimating a group mean. No pooling occurs in this case (right panel in Figure \@ref(fig:pooling)). A fixed factor return such means.

Third, the data of the different groups can be partially pooled (i.e., treated as a random effect). Thereby, the group means are weighted averages of the population mean and the unpooled group means. The weights are proportional to sample size and the inverse of the variance (see @Gelman.2007, p. 252). Further, the overall mean (the "population mean") is close to the mean of the group-specific means, thus, every group is weighed similarly for calculating this overall mean. In contrast, in the complete pooling case, the groups get weights proportional to their sample sizes, i.e. each observation has the same weight. In the no-pooling case, there is no overall mean.



Complete pooling    | Partial pooling       | No pooling        | 
:-------------------|:----------------------|:------------------|
 $\hat{y_i} = \beta_0$ \ $y_i \sim normal(\hat{y_i}, \sigma^2)$ | $\hat{y_i} = \beta_0 + b_{g[i]}$ \ $b_g \sim normal(0, \sigma_b^2)$ \ $y_i \sim normal(\hat{y_i}, \sigma^2)$  | $\hat{y_i} = \beta_{0[g[i]]}$ \ $y_i \sim normal(\hat{y_i}, \sigma_g^2)$ |  


```{r pooling, echo=FALSE, results='hide', fig.cap='Three possibilities to obtain group and/or population means for grouped data: complete pooling, partial pooling, and no pooling. Open symbols = data, orange dots with vertical bars = group means with 95% uncertainty intervals, horizontal black line with shaded interval = population mean with 95% uncertainty interval.', fig.asp=0.45}


# simulate unbalance data from ngroup groups
set.seed(0470)
ngroup <- 10         # number of groups
sigma <- 2.5         # residual variance (standard deviation)
sigma_b <- 3         # between-group variance (standard deviation)
group.means <- rnorm(ngroup, 15, sigma_b)               # simulate group means
npg <- rbinom(ngroup, prob=runif(ngroup), size=100)     # draw sample sizes per group at random between 0 and 100
y <- NULL
for(i in 1:ngroup) y <- c(y, rnorm(npg[i], group.means[i], sigma))         # simulate data
group <- factor(rep(c(1:ngroup), npg))                                     # create the group-factor
# end of data simulations



ylimes <- c(floor(min(y)), ceiling(max(y)))
x <-   jitter(as.numeric(group))
ps <- 1.2 # point size


# complete pooling
par(mfrow=c(1,3), mar=c(5, 1,2,1), oma=c(0,3,0,0))
plot(y~x,ylim=ylimes, xlab="group", ylab="y", las=1, cex.lab=1.4, 
     cex.axis=1.2, xaxt="n", main="complete pooling", cex.main=1.7)
axis(1, at=1:ngroup, labels=levels(group), cex.axis=1.2)
mtext("y", side=2, line=3)
m.y <- mean(y)
sd(y)
se.y <- sd(y)/sqrt(length(y))

rect(0, m.y-1.96*se.y, 21, m.y+1.96*se.y, col=grey(0.6), border=NA)
abline(h=m.y)
#points(mean(1:ngroup), m.y, pch=16, cex=ps, col="orange")
points(y~x)

# partial pooling
mod <- lmer(y~1+(1|group))
summary(mod)
m.ppypg <- fixef(mod) + ranef(mod)$group
popmean <- fixef(mod)
box()

# simulates confidence intervals for means
bsim <- sim(mod, n.sim=2000)
ranefsim <- bsim@ranef$group

sem.ppypg <- apply(ranefsim[,,1], 2, sd)
sem.popmean <- sd(bsim@fixef[,1])


plot(y~x, type="n",   ylim=ylimes, xlab="group", ylab=NA, yaxt="n", las=1, cex.lab=1.4, 
    cex.axis=1.2, xaxt="n", main="partial pooling", cex.main=1.7)
axis(1, at=1:ngroup, labels=levels(group), cex.axis=1.2)

# insert population mean
rect(0, popmean-1.96*sem.popmean, 21, popmean+1.96*sem.popmean, col=grey(0.6), border=NA)
abline(h=popmean)

points(y~x)


segments(1:ngroup, unlist(m.ppypg)-1.96*sem.ppypg, 1:ngroup, unlist(m.ppypg)+1.96*sem.ppypg, lwd=2, lend="butt", col="orange")
points(1:ngroup, unlist(m.ppypg), pch=16, cex=ps, col="orange")
box()

# no pooling
plot(y~x,ylim=ylimes, xlab="group", ylab=NA, yaxt="n", las=1, cex.lab=1.4, 
     cex.axis=1.2, xaxt="n", main="no pooling", cex.main=1.7)
axis(1, at=1:ngroup, labels=levels(group), cex.axis=1.2)
m.ypg <- tapply(y, group, mean)
se.ypg <- tapply(y, group, function(x) sd(x)/sqrt(length(x)))
segments(1:ngroup, m.ypg-1.96*se.ypg, 1:ngroup, m.ypg+1.96*se.ypg, lwd=2, lend="butt", col="orange")
points(1:ngroup, m.ypg, pch=16, cex=ps, col="orange")

```


What is the advantage of analyses using partial pooling (i.e., mixed, hierarchical, or multilevel modelling) compared to the complete or no pooling analyses? Complete pooling ignores the grouping structure of the data. As a result, the uncertainty interval of the population mean may be too narrow. We are too confident in the result because we assume that all observations are independent when they are not. This is a typical case of pseudoreplication. On the other hand, the no pooling method (which is equivalent to treating the factor as fixed) has the danger of overestimation of the among-group variance because the group means are estimated independently of each other. The danger of overestimating the among-group variance is particularly large when sample sizes per group are low and within-group variance large. In contrast, the partial pooling method assumes that the group means are a random sample from a common distribution. Therefore, information is exchanged between groups. Estimated means for groups with low sample sizes, large variances, and means far away from the population mean are shrunk towards the population mean. Thus, group means that are estimated with a lot of imprecision (because of low sample size and high variance) are shrunk towards the population mean. How strongly they are shrunk depends on the precision of the estimates for the group specific means and the population mean. 

An example will help make this clear. Imagine that we measured 60 nestling birds from 10 nests (6 nestlings per nest) and found that the average nestling mass at day 10 was around 20&nbsp;g with an among-nest standard deviation of 2&nbsp;g. Then, we measure only one nestling from one additional nest (from the same population) whose mass was 12&nbsp;g. What do we know about the average mass of this new nest? The mean of the measurements for this nest is 12&nbsp;g, but with n = 1 uncertainty is high. Because we know that the average mass of the other nests was 20&nbsp;g, and because the new nest belonged to the same population, a value higher than 12&nbsp;g is a better estimate for an average nestling mass of the new nest than the 12&nbsp;g measurement of one single nestling, which could, by chance, have been an exceptionally light individual. This is the shrinkage that partial pooling allows in a mixed model. Because of this shrinkage, the estimates for group means from a mixed model are sometimes called shrinkage estimators. A consequence of the shrinkage is that the residuals are positively correlated with the fitted values. 
To summarize, mixed models are used to appropriately estimate among-group variance, and to account for non-independency among data points.

## Fitting a normal linear mixed model in R

To introduce the linear mixed model, we use repeated hormone measures at nestling barn owls *Tyto alba*. The cortbowl data set contains stress hormone data (corticosterone, variable "totCort") of nestling barn owls which were either treated with a corticosterone implant, or with a placebo-implant as the control group. The aim of the study was to quantify the corticosterone increase due to the corticosterone implant [@Almasi.2009]. In each brood, one or two nestlings were implanted with a corticosterone implant and one or two nestlings with a placebo implant (variable ‘Implant’). Blood samples were taken just before implantation, and at days 2 and 20 after implantation. 

```{r }
data(cortbowl)
dat <- cortbowl
dat$days <- factor(dat$days, levels=c("before", "2", "20")) 
str(dat)  # the data was sampled in 2004,2005, and 2005 by the Swiss Ornithologicla Institute
```

In total, there are 287 measurements of 151 individuals (variable ‘Ring’) of 54 broods. Because the measurements from the same individual are non-independent, we use a mixed model to analyze these data. Two additional arguments for a mixed model are: a) The mixed model allows prediction of corticosterone levels for an ‘average’ individual, whereas the fixed effect model allows prediction of corticosterone levels only for the 151 individuals that were sampled. And b) fewer parameters are needed. If we include individual as a fixed factor, we would use 150 parameters, while the random factor needs a much lower number of parameters (only one classical parameter: the among-individual variance; the random factor increases model complexity by more than 1 parameter - by how many depends on the data, but it is usually much less than what is needed for a fixed factor with the same number of levels).
We first create a raw-data plot to show the development for each individual, separately for owls receiving corticosterone versus owls receiving a placebo (Figure \@ref(fig:corttest)).


```{r corttest, fig.asp=0.45, fig.cap="Total corticosterone before and at day 2 and 20 after implantation of a corticosterone or a placebo implant. Lines connect measurements of the same individual.", echo=FALSE}
par(mfrow=c(1,2), mar=c(4,0,2,0.2), oma=c(0,5,0,0))
for(treat in levels(dat$Implant)){
  plot(as.numeric(dat$days), dat$totCort, 
       type="n",xlim=c(0.5, 3.5),
       las=1, yaxt="n", xaxt="n", xlab="Days after implantation")
  axis(1, at=1:3, labels=c("before", "2", "20"))
  if(treat=="C") { axis(2, las=1)
  	               mtext("Corticosterone",3,line=1) }
  if(treat=="P")   mtext("Placebo",3,line=1)
  inds <- dat$Ring[dat$Implant==treat]
  for(i in inds){
  lines(dat$days[dat$Ring==i], dat$totCort[dat$Ring==i])
  }
}
mtext("Total corticosterone [ng/ml]", side=2, outer=TRUE, line=3, cex=1.2)
```

We fit a normal linear model with "Ring" as a random factor, and "Implant", "days" and the interaction of "Implant" $\times$ "days" as fixed effects. Note that both "Implant" and "days" are defined as factors, thus R creates indicator variables for all levels except the reference level. Later, we will also include "Brood" as a grouping level; for now, we ignore this level and start with a simpler (less perfect) model for illustrative purposes.

\[
\begin{aligned}
&\hat{y_i} = \beta_0 + b_{Ring_i} + \beta_1 I(days=2) + \beta_2 I(days=20) + \beta_3 I(Implant=P) \\
&\quad + \beta_4 I(days=2) I(Implant=P) + \beta_5 I(days=20) I(Implant=P) \\
&b_{Ring} \sim normal(0, \sigma_b) \\
&y_i \sim normal(\hat{y_i}, \sigma)
\end{aligned}
\]

Several different functions to fit a mixed model have been written in R: `lme`, `gls`, `gee` have been the first ones. Then `lmer` followed, and now, `stan_lmer` and `brm` allow to fit a large variety of hierarchical models. We here start with using `lmer` from the package lme4, because it is a kind of basic function also for `stan_lmer`and `brm`. Further, `sim` can only work with lmer-objects but none of the others. To work with lmer, we usually load the package arm which contains the function `sim` and also automatically loads lme4.

The function `lmer` is used similarly to the function `lm`. The only difference is that the random factors are added in the model formula within parentheses, e.g. ‘+ (1|Ring)’. The ’1’ stands for the intercept and the ‘|’ means ‘grouped by’. ‘(1|Ring)’, therefore, adds the random deviations for each individual to the average intercept. These deviations are the $b_{Ring}$ in the model formula above.

To fit the model to our example data, we log-transformed the corticosterone values (i.e. the outcome variable) to achieve normally distributed residuals. After having fitted the model, in real life, we always first inspect the residuals before we look at the model output. Here, we skip this point to explain how the model is constructed right after having shown the model code. But we will come back to  the residual analyses.


```{r }
mod <- lmer(log(totCort) ~ Implant + days + Implant:days + (1|Ring), 
            data=dat, REML=TRUE)
mod
```


The output of the lmer-object tells us that the model was fitted using the REML-method, which is the restricted maximum likelihood method. The "REML criterion" is the statistic describing the model fit for a model fitted by REML. The comes the more interesting part: the parameter estimates. These are grouped into a random effects and fixed effects section. The random effects section gives the estimates for the among-individual standard deviation of the intercept ($\sigma_{Ring} =$ `r round(sqrt(as.numeric(VarCorr(mod)[1])),2)`) and the residual standard deviation ($\sigma =$ `r round(summary(mod)$sigma,2)`). The fixed effects section gives the estimates for the intercept ($\beta_0 =$ `r round(fixef(mod)[1],2)`), which is the mean logarithm of corticosterone for an ‘average’ individual that received a corticosterone implant at the day of implantation. The other model coefficients are defined as follows: The difference in the logarithm of corticosterone between placebo- and corticosterone-treated individuals before implantation ($\beta_1 =$ `r round(fixef(mod)[2],2)`), the difference between day 2 and before implantation for the corticosterone-treated individuals ($\beta_2 =$ `r round(fixef(mod)[3],2)`), the difference between day 20 and before implantation for the corticosterone-treated individuals ($\beta_3 =$ `r round(fixef(mod)[4],2)`), and the interaction parameters which tell us how the differences between day 2 and before implantation ($\beta_4 =$ `r round(fixef(mod)[5],2)`), and day 20 and before implantation ($\beta_5 =$ `r round(fixef(mod)[6],2)`), differ for the placebo-treated individuals compared to the corticosterone treated individuals. Of course, these interpretations of the fixed effects are the same as in non-mixed models.

Neither the model output shown above nor the summary function (not shown) give any information about the proportion of variance explained by the model such as an $R^2$. The reason is that it is not straightforward to obtain a measure of model fit in a mixed model, and different definitions of $R^2$ exist [@Nakagawa.2013]. 

The function `fixef` extracts the estimates for the fixed effects, the function `ranef` extracts the estimates for the random deviations from the population intercept for each individual. The `ranef`-object is a list with one element for each random factor in the model. We can extract the random effects for each ring using the `$Ring` notation. 

```{r}
round(fixef(mod), 3)
head(ranef(mod)$Ring) # print the first 6 Ring effects
```

## Restricted maximum likelihood estimation (REML)
<!-- we have not yet explained the ML-method. in the old book, Chapter 5. we need to find a place for ML-method ___ pko15.8.25: inserted link to 9.3-->
For a mixed model the restricted maximum likelihood method is used by default instead of the maximum likelihood (ML) method (see Chapter \@ref(likelihood)). The reason is that the ML-method underestimates the variance parameters because this method assumes that the fixed parameters are known without uncertainty when estimating the variance parameters. However, the estimates of the fixed effects have uncertainty. The REML method uses a mathematical trick to make the estimates for the variance parameters independent of the estimates for the fixed effects. We recommend reading the very understandable description of the REML method in @Zuur.2009. For our purposes, the relevant difference between the two methods is that the ML-estimates are unbiased for the fixed effects but biased for the random effects, whereas the REML-estimates are biased for the fixed effects and unbiased for the random effects. However, when sample size is large compared to the number of model parameters, the differences between the ML- and REML-estimates become negligible. As a guideline, use REML if the interest is in the random effects (variance parameters), and ML if the interest is in the fixed effects. The estimation method can be chosen by setting the argument ‘REML’ to ‘FALSE’ (default is ‘TRUE’).

```{r}
mod <- lmer(log(totCort) ~ Implant + days + Implant:days + (1|Ring), 
            data=dat, REML=FALSE)  # using ML
```

When we fit the model by `stan_lmer` from the rstanarm-package or `brm` from the brms-package, i.e., using the Bayes theorem instead of ML or REML, we do not have to care about this choice (of course!). The result from a Bayesian analyses is unbiased for all parameters (at least from a mathematical point of view - also parameters from a Bayesian model can be biased if the model violates assumptions or is confounded). 

## Assessing model assumptions
As with a simple linear model, the assumptions are carefully checked before inference is drawn from a mixed model. The assumptions are, as explained in Chapter \@ref(residualanalysis), that the residuals are independent and identically distributed (iid). In principle, the same methods described in Chapter \@ref(residualanalysis) are used to assess violation of model assumptions in mixed models. However, the function `plot` does not produce the standard diagnostic residual plots from an `lmer` object. Therefore, these plots have to be coded by hand.

In the first plot of Figure \@ref(fig:mermodplot) we see that the residuals scatter around zero with a few exceptions in the lower left part of the panel. A positive correlation between the residuals and the fitted values (not present in the example data) would not bother us statistically in the case of a mixed model, but it indicates strong shrinkage and may have biological meaning.

The few small measurements that do not fit well to the model are also recognizable in the QQ plot of the residuals (a banana-like deviation from the straight line at the left edge of the data) and when plotting the square root of the absolute values of the residuals against the fitted values (second and third plots in Figure \@ref(fig:mermodplot)). Because the number of such cases is low and all other observations seem to fulfill the model assumptions well, we accept the slight lack of fit. But we are aware of the fact that model predictions for small corticosterone levels are unreliable.

In addition to the checks presented in Chapter \@ref(residualanalysis), the assumption that the random effects, that is the values of $b_{Ring}$, are normally distributed, needs to be checked. We do this using a QQ plot (fourth plot in Figure \@ref(fig:mermodplot)). Note that we need to extract the $b_{Ring}$ using "[,1]" because the ranef object is two-dimensional.


```{r mermodplot, fig.asp=1, fig.cap="Diagnostic residual and random effect plots to assess model assumptions of the corticosterone model. Upper left: residuals versus fitted values. Upper right: Normal QQ plot of the residuals. Lower left: square-root of the absolute values of the residuals versus fitted values. Lower right: Normal QQ plot of the random effects."}
par(mfrow=c(2,2))
scatter.smooth(fitted(mod),resid(mod)); abline(h=0, lty=2)
title("Tukey-Anscombe Plot") # residuals vs. fitted

qqnorm(resid(mod), main="normal QQ-plot, residuals") # qq of residuals
qqline(resid(mod))
scatter.smooth(fitted(mod), sqrt(abs(resid(mod)))) # res. var vs. fitted

qqnorm(ranef(mod)$Ring[,1], main="normal QQ-plot, random effects")
qqline(ranef(mod)$Ring[,1]) # qq of random effects
```

We do not see a serious deviation in the distribution of the random effects from the normal distribution.

## Drawing conclusions
We use the function `sim` to draw 2000 random values from the joint posterior distribution of the model parameters; that is, we draw 2000 values for each parameter while taking the correlation between the parameters into account.

```{r}
nsim <- 2000
bsim <- sim(mod, n.sim=nsim)
str(bsim)
```

The object produced by the `sim` function when applied to a mer object (= object produced by the functions `lmer` or `glmer`) contains three slots (remember that slots are addressed using the `@` sign in R). The slot “fixef” is a matrix with as many columns as there are parameters in the fixed part of the model. The number of rows corresponds to the number of simulations (we have saved this number in the object “nsim”). The slot “ranef” is a list that contains one element for each random factor. In the previous example, there is only one random factor (“Ring”). Therefore, the list contains only one element.
Each element of the ranef slot is a three-dimensional array where the first dimension represents the number of simulations (2000 in our case), the second dimension is the number of groups (factor levels; here this is the number of individuals), and the third dimension corresponds to the number of parameters that are grouped by the specific factor. In the previous example, we have included only a random intercept in the model. Therefore, this dimension has a length of one. In the following we will fit models with more parameters per random effect.
From the simulated values (i.e. draws from the joint posterior distribution), the 2.5% and 97.5% quantiles can be used for the 95% credible interval:

```{r}
round(apply(bsim@fixef, 2,quantile, prob=c(0.025,0.5,0.975)),3)
```

Some effort is needed to interpret models with interactions (independent of whether it is a mixed model or not). We see that in the corticosterone-treated nestlings, the logarithm of the corticosterone measure increases from before implantation to day 2 by 1.7 (95% compatiblity interval CI: 1.4-1.9), which is quite substantial. To get this increase for the placebo-treated individuals, we have to add the interaction parameter, thus the increase in placebo nestlings is 1.7-1.7 = 0. The interaction parameter, -1.7 (95% CI: -2.1 to -1.4), measures the difference between placebo and corticosterone nestlings in their response to the treatment; it is, therefore, an important result.
To better see what really happens, we often plot the fitted values with its CI and the observations in one plot. To this end, we first prepare a new data frame that contains a row for each factor level (“Implant” and “days”). Then, the fitted value for each of the factor-level combinations is calculated 2000 times (once for each set of model parameters from the simulated posterior distribution) to obtain 2000 simulated values from the posterior distribution of the fitted values. The 2.5% and 97.5% quantiles of these fitted values are used as lower and upper bounds of the 95% compatibility interval.

```{r}
newdat <- expand.grid(Implant=factor(c("C","P"),levels=levels(dat$Implant)),
                      days=factor(c("before",2,20),levels=levels(dat$days)))
Xmat <- model.matrix(~ Implant + days + Implant:days, data=newdat)
fitmat <- matrix(ncol=nsim, nrow=nrow(newdat))
for(i in 1:nsim) fitmat[,i] <- Xmat %*% bsim@fixef[i,] # fitted values
newdat$lower <- apply(fitmat, 1, quantile, prob=0.025)
newdat$upper <- apply(fitmat, 1, quantile, prob=0.975)
newdat$fit <- Xmat %*% fixef(mod)
```

The fitted values given in Figure \@ref(fig:cortdaysplot), together with their uncertainty measures (compatibility intervals), take into account that we had repeated measures for each individual.

```{r cortdaysplot, echo=FALSE, fig.cap="Predicted total corticosterone values with 95% CI of placebo-implanted nestlings (closed symbol) and corticosterone-implanted nestlings (open symbol) in relation to days after implantation. Blue dots are raw data of placebo-implanted nestlings, and orange dots are raw data of corticosterone-implanted nestlings."}

par(mfrow=c(1,1), mar=c(2,2,1,1), omi= c(0.5,0.5,0,0))     # "mar" sets the margins (lower, left, upper, right) around the plot

indexP <- newdat$Implant=='P'
indexC <- newdat$Implant=='C'
a <- 1
dat$daysNum <- ifelse(dat$days=='before', 0, as.character(dat$days)) # nummeric day variable
dat$daysNum <- as.numeric(dat$daysNum) # nummeric day variable

plot(seq(-2,22,1), seq(-0.1,4.8,length=25), yaxt="n", xaxt="n", type="n", xlab="", ylab="", las=2, cex.lab=a,
     main="", cex.main=a, font.main=1)
points(jitter(dat$daysNum[dat$Implant=='P']-0.4), log(dat$totCort[dat$Implant=='P']), lwd=2 ,pch=16, col="blue",   cex=0.5)          # Placebo raw data
points(jitter(dat$daysNum[dat$Implant=='C']+0.2), log(dat$totCort[dat$Implant=='C']), lwd=2 ,pch=16, col="orange", cex=0.5, lty=2)   # Cort raw data

segments(c(0,2,20)-c(0.4,0.4,0.4), newdat$lower[indexP], c(0,2,20)-c(0.4,0.4,0.4), newdat$upper[indexP], lty=1, lwd=2, col="black" ) # CrI 
points(c(0,2,20)-c(0.4,0.4,0.4), newdat$fit[indexP], lwd=2 ,pch=16, col="black", cex=1.2)     # Placebo 

segments(c(0,2,20)+c(0.2,0.2,0.2), newdat$upper[indexC], c(0,2,20)+c(0.2,0.2,0.2), newdat$lower[indexC],lty=1, lwd=2, col="black" )  # CrI 
points(c(0,2,20)+c(0.2,0.2,0.2), newdat$fit[indexC], lwd=1 ,lty=1, pch=21, bg="white", col="black", cex=1.2) # CORT 

axis(side=2, labels=F,at=seq(0,4.8,0.4),line=0,tcl=-0.3,las=1)
axis(side=2, labels=seq(0,4.8,0.4),at=seq(0,4.8,0.4),line=0,tcl=-0.3,las=1, mgp=c(3,0.5,0),cex.axis=a)    
axis(side=1, labels=c(NA, 2,20),at=c(0, 2,20),line=0,tcl=-0.3,las=1)
axis(side=1, labels=c("before"),at=c(-0.5),line=0,tcl=0,las=1)

mtext(side=2,line=3,adj=0.5,cex=a,font=2,"Total corticosterone [log, ng/ml]",las=0,outer=FALSE)
mtext(side=1,line=3,adj=0.5,cex=a,font=2,"Days after implantation",outer=FALSE)

points(c(10,10),c(4.5,4.8),pch=21,bg=c("black","white"))
text(c(11,11),c(4.5,4.8),c("placebo", "corticosterone"),adj=c(0,0.5))
```
## Random intercept and slope
In the preceding model, only the intercept $\beta_0$ was modeled per individual (the model allowed for between-individual variance in $\beta_0$). But a random effect does not need to be restricted to the intercept. Any parameter can be modeled, if the data allow. For example, in the previous model we cannot include an individual-specific difference between corticosterone and placebo treatment because each individual obtained only one treatment. Therefore, the data do not contain information about between-individual differences in the treatment effect, and it does not make sense to include such a structure in the model.
In another study on barn owls, we were interested in the effect of corticosterone on growth rate. Here, we measured wing length (as a proxy for size) at different ages of individuals that had been treated either with corticosterone or with a placebo implant. We used the slope of the regression line for wing length on age as a growth rate measure, and we were interested in the difference in this slope between corticosterone- and placebo-implanted individuals.
We expected that growth rate differed between individuals due to between-individual differences in body condition and also because the age at which the implant was implanted differed between the individuals because barn owl nestlings hatch asynchronously (the implantation was done on the same day for all the nestlings in a nest). Therefore, we modeled the slope of the regression line for each individual. Otherwise, our confidence in the (population) slope parameter would be too high (the compatibility intervals would be too narrow). This is because individual-specific slopes in the data produce a kind of pseudoreplication when equal slopes between individuals are assumed in the model (@Schielzeth.2009).
The data for the growth rate study are in the wingbowl data set. In total, we have 209 measurements of 86 individuals (variable “Ring”) from 24 broods.
In the model, we include “age” (as a continuous covariate), “implant” (as a fixed effect), and their interaction in the fixed part; and “ring” (= id of individual) is included as a random effect. We model both the intercept and the slope for the covariate “age” dependent on “ring.” We use this notation with $b_{Ring}$ being an individual-specific deviation from the population mean parameter value, but we add a second numerical subscript, $b_{1,Ring}$, to indicate the random intercept and $b_{2,Ring}$ for the random slope. The two random parameters are assumed to follow a multivariate normal distribution (MVNorm); that is, they are both normally distributed and are assumed to be correlated and this correlation is estimated. Hence, the formula for the random intercept and random slope model is:

\[
\begin{aligned} 
  &\hat{y_i} =\beta_0 + b_{1,Ring_i} + (\beta_1 + b_{2,Ring_i}) age_i + \beta_2 I(Implant=P)+\beta_3 age_i I(Implant=P) \\
  &y_i \sim normal(\hat{y_i}, \sigma^2) \\
  &\boldsymbol{b}_{1:2,Ring} \sim MVnormal(\boldsymbol{0,\Sigma})
\end{aligned}
\]

The vector $\boldsymbol{b}_{1:2,Ring}$ contains the two parameters $b_{1,Ring}$ and $b_{2,Ring}$. The matrix $\boldsymbol{\Sigma}$ contains the variances of and the covariances between the intercept and the slope. The notation `(Age|Ring)` means that both the intercept and the Age-effect are grouped by Ring. We find it advisable to center and scale covariates, especially for mixed models with some complexity because non-centered covariates lead to a stronger correlation between the estimated parameters, which may cause nonconvergence of the fitting algorithm. Hence, we center and scale the variable “Age”:

```{r}
data(wingbowl)
dat <- wingbowl
dat$Age.z <- scale(dat$Age)
mod <- lmer(Wing ~ Age.z + Implant + Age.z:Implant + (Age.z|Ring),
            data=dat, REML=FALSE)
mod
```

The estimate of the between-nestling standard deviation for the intercept is 6.4 and for the age-effect (slope), this value is 1.9. We see that there is a negative correlation between the intercept and the slope (-0.12). This is not unusual, and it would be even stronger with noncentered predictors: this means we can find different regression lines that fit the data similarly well when we increase the intercept and simultaneously decrease the slope.
We can use the diagnostic residual plots as described in Chapter \@ref(residualanalysis), and the R code of the previous section, to produce a QQ plot of the random effects. Because two parameters were modeled per individual, we have to produce two different QQ plots to assess whether the random effects are normally distributed. The different parameters for each random effect are extracted from the `ranef` object using the squared brackets because the random effects are given as a matrix containing one row per individual and one column per parameter (here: intercept and age-effect).

```{r, results='hide'}
qqnorm(ranef(mod)$Ring[,1]) # intercept
qqline(ranef(mod)$Ring[,1])
qqnorm(ranef(mod)$Ring[,2]) # slope
qqline(ranef(mod)$Ring[,2]) # plots not shown
```

The diagnostic residual plots did not indicate strong violation of the model assumptions; therefore, we can start drawing inferences from the model. Our question was how strongly does corticosterone affect growth rate? From the model output we see that individuals with a placebo implant grow 2.2&nbsp;mm more per standard deviation of age, that is, `2.2/sd(dat$Age)`&nbsp;= 0.4&nbsp;mm per day compared to the individuals with a corticosterone implant. We can get the 95% CI of the parameter estimates using `sim`.

```{r}
nsim <- 2000
bsim <- sim(mod, n.sim=nsim)
apply(bsim@fixef, 2, quantile, prob=c(0.025, 0.975))
```

The CI for the interaction effect of 0.4&nbsp;mm, on the original Age-scale, is:

```{r}
quantile(bsim@fixef[,"Age.z:ImplantP"]/sd(dat$Age), prob=c(0.025,0.975))
```

Thus, given the data and the model, we are 95% sure that the wings of placebo nestlings grow between 0.16&nbsp;mm and 0.66&nbsp;mm faster per day than the wings of corticosterone nestlings. To be better able to assess the biological relevance of this effect, we may want to plot the two regression lines (averaged over the individuals) as well as the individual-specific regression lines (\@ref(fig:wingagecourtplot)). To do so, we calculate the fitted values for each age and implant combination 2000 times, each with a different set of model parameters from their posterior distribution.

```{r}
newdat <- expand.grid(Age=seq(23, 45, length=100),
                      Implant=levels(dat$Implant))
newdat$Age.z <- (newdat$Age - mean(dat$Age))/sd(dat$Age)
Xmat <- model.matrix(~Age.z + Implant + Age.z:Implant, data=newdat)
fitmat <- matrix(ncol=nsim, nrow=nrow(newdat))
for(i in 1:nsim) fitmat[,i] <- Xmat %*% bsim@fixef[i,]
newdat$lower <- apply(fitmat, 1, quantile, prob=0.025)
newdat$upper <- apply(fitmat, 1, quantile, prob=0.975)
```

We do not extract the mean of the posterior distribution of the fitted values because we use the ML estimates for drawing the mean regression lines. These estimates are not subject to simulation error. Note that we use Age.z on the x-axis, but we label the x-axis with back-transformed values so that we are able to use the `abline` function to draw the regression lines directly from the model parameters.

To draw the individual-specific regression lines, we add the individual-specific deviations from the intercept and the slope, respectively, to the population intercept and slope.We do this in a separate plot so as not to overload the figure.

```{r wingagecourtplot, fig.cap="*Left*: Population regression lines (bold lines) with 95% compatibility intervals (semitransparent color) for the corticosterone (orange) and placebo (blue) treated barn owl nestlings. *Right*: Individual-specific regression lines. Circles are the raw data."}

par(mfrow=c(1,2), mar=c(5,1,1,0.1), oma=c(0,4,0,0))
plot(dat$Age.z, dat$Wing, pch=1, cex=0.8, las=1,xlab="Age (days)",
     col=c("orange", "blue")[as.numeric(dat$Implant)],ylab=NA, xaxt="n")
at.x_orig <- seq(25,45,by=5) # values on the x-axis, original scale
at.x <- (at.x_orig-mean(dat$Age))/sd(dat$Age) # transformed scale
axis(1, at=at.x, labels=at.x_orig) # original values at transformed
mtext("Wing length (mm)", side=2, outer=TRUE, line=2, cex=1.2, adj=0.6)
abline(fixef(mod)[1], fixef(mod)[2], col="orange", lwd=2) # for C
abline(fixef(mod)[1]+fixef(mod)[3], fixef(mod)[2]+fixef(mod)[4], col="blue", lwd=2) # for P
# add transparent polygons to visualize the 95% CI
for(i in 1:2){
  index <- newdat$Implant==levels(newdat$Implant)[i]
  polygon(c(newdat$Age.z[index], rev(newdat$Age.z[index])),
          c(newdat$lower[index], rev(newdat$upper[index])),
          border=NA, col=c(rgb(1,0.65,0,0.5), rgb(0,0,1,0.5))[i])
}
legend(x=-1.5,y=100, c("corticosterone", "placebo"),pch=c(1,1),col=c("orange","blue"),
       bty="n",lwd=2,cex=1, pt.cex=1.2)

# individual-specific regression lines in a separate plot:
plot(dat$Age.z, dat$Wing, pch=1, cex=0.8, las=1, col=c("orange", "blue")[as.numeric(dat$Implant)],
     xlab="Age (days)", ylab=NA, yaxt="n", xaxt="n")
at.x_orig <- seq(25,45,by=5)
at.x <- (at.x_orig - mean(dat$Age))/sd(dat$Age)
axis(1, at=at.x, labels=at.x_orig)
indtreat <- tapply(dat$Implant, dat$Ring, function(x) as.character(x[1]))
for(i in 1:86){
  if(indtreat[i]=="C") 
    abline(fixef(mod)[1]+ranef(mod)$Ring[i,1],
           fixef(mod)[2]+ranef(mod)$Ring[i,2],col="orange") 
  else
    abline(fixef(mod)[1]+fixef(mod)[3]+ranef(mod)$Ring[i,1],
           fixef(mod)[2]+fixef(mod)[4]+ranef(mod)$Ring[i,2],col="blue")
}

```

We see a discernible effect of corticosterone on growth rate such that the wing length of corticosterone-treated nestlings is, on average, around 1&nbsp;cm smaller than in placebo-treated individuals at the end of the nestling phase.

## Nested and crossed random effects

Random factors can be nested or crossed. Each level of a factor that is nested within another factor occurs only in one level of the other factor (Figure \@ref(fig:nestedrandomplot), left). For example, the factor "nestling" is nested in the factor "nest" because the same nestling cannot be in two nests. In contrast, when two factors are crossed, all possible combinations of the factor levels occur in the data set (Figure \@ref(fig:nestedrandomplot), right). For example, the factors "month" and "year" are crossed, because all months occur in every year.
<br>

```{r nestedrandomplot, fig.align='center', echo=FALSE, fig.cap="Nested and crossed structures of two factors. In the left panel, each level of the factor &quot;individual&quot; only occurs in one level of the factor &quot;nest&quot;. These are called nested effects. In the right panel, each level of the factor &quot;species&quot; occurs in all levels of the factor &quot;field&quot;. Therefore, these factors are called crossed."}
knitr::include_graphics('images/nested_crossed.jpg', dpi = 150)
```


It is important to specify factors as nested and crossed random factors, because a falsely specified structure leads to indecipherable results. If unique level names are used (in contrast to starting with the number 1 in each group), the nested structure is defined in the data and there is no need to explicitly specify the nested design in the `lmer` (or `glmer`, see Chapter \@ref(glmm)) function; if nestlings (or other levels nested in another factor) are not labeled uniquely (i.e., different nestlings from different nests have the same name), the nesting structure has to be specified in the model formula. The following is an example of a nested random effect and one of a crossed random effect.

In the two barn owl example data sets described earlier, the individuals were actually not independent because they were grouped in nests. Thus, we should have included nest as another random factor in the two models. Because each individual only appears in one nest, these two random factors are nested. There are two possible ways to specify nested random effects in the function `lmer`. The first is to add the factor nest ("Brood") as a second random effect in the model formula. This only fits nested random effects if the nested structure is clear from the names of the factor levels, because the nested structure is not explicitly defined in the model formula; all nestlings must have a unique name, thereby, it becomes clear that each nestling belongs to only one nest (is nested within nest).

```{r}
data(cortbowl)
dat <- cortbowl
mod <- lmer(log(totCort) ~ Implant + days + Implant:days
            + (1|Brood) + (1|Ring), data=dat, REML=FALSE)
mod
```

The second possibility is to define explicitly the nested structure in the model formula using the "F1/F2" notation ("F2 is nested in F1").

```{r}
mod <- lmer(log(totCort) ~ Implant + days + Implant:days
            + (1|Brood/Ring), data=dat, REML=FALSE)
summary(mod)$varcor
```

These two models are the same, hence not all model output is repeated. The only difference is in the name of the individual random factor: it is called "Ring" in the first version, whereas in the second version it is called "Ring:Brood", meaning "Ring nested in Brood".

To specify crossed random effects, we can only use the first specification in the previous example. For example, in Ellenberg's data (Chapter \@ref(lm)), six different grass species were grown in four different situations: two tanks in each of two years, and the two tanks contained different soil. This four-level factor has been called "gradient" by @Hector.2012. Four species were grown in all four gradients and two species were grown in only two of the gradients. Above-ground biomass was measured for 11 different water conditions within each species-gradient combination.

```{r}
data(ellenberg)
ellenberg$gradient <- paste(ellenberg$Year, ellenberg$Soil)
table(ellenberg$Species, ellenberg$gradient)
```

We assume that the six grass species are a random sample from the family Poaceae (true grasses) and we may be interested in the general relationship between water condition (distance to ground water; using a linear and a quadratic term) and Poaceae biomass, as well as in species-specific reactions to water conditions. Therefore, we treat species as a random factor. We also include gradient as a random factor to correct for any between-gradient variance.

```{r warning=FALSE}
ellenberg$water.z <- as.numeric(scale(ellenberg$Water))
mod <- lmer(log(Yi.g) ~ water.z + I(water.z^2)
            + (water.z + I(water.z^2)|Species) + (1|gradient), data=ellenberg)
```

We did not find any suspicious pattern in the residuals and, therefore, plot the species-specific and the overall (for all Poaceae) relationship between water gradient and biomass in a figure. We see that the average biomass of Poaceae does not change with distance to ground water, but the different species react quite differently to the water condition (\@ref(fig:biomasswaterplot)).

```{r biomasswaterplot, echo=F, fig.cap="Average biomass of Poaceae plants (black line with 95% compatibility interval in gray), and the species-specific biomasses (colored lines), in relation to water condition. Dot are the raw data, each color is a different species.", fig.width=5, fig.height=5}

set.seed(0470)
nsim <- 5000
bsim <- sim(mod, n.sim=nsim)

newdat <- expand.grid(Water=seq(-5,140, length=100), Species= levels(ellenberg$Species)) 
newdat$water.z <- (newdat$Water - mean(ellenberg$Water))/sd(ellenberg$Water)
Xmat <- model.matrix(~water.z + I(water.z^2), data=newdat)
fitmat <- matrix(nrow=nrow(newdat), ncol=nsim)
fitmatpop <- matrix(nrow=nrow(newdat), ncol=nsim)

for(a in 1:6){
  index <- newdat$Species==levels(ellenberg$Species)[a]
  for(i in 1:nsim){
    b <- bsim@fixef[i,] + bsim@ranef$Species[i,a,]
    fitmat[index,i] <- Xmat[index,]%*%b
    fitmatpop[index,i] <- Xmat[index,]%*%bsim@fixef[i,]
  }
}

newdat$fit <- apply(fitmat, 1, mean)
newdat$lower <- apply(fitmat, 1, quantile, prob=0.025)
newdat$upper <- apply(fitmat, 1, quantile, prob=0.975)
newdat$fitpop <- apply(fitmatpop, 1, mean)
newdat$lowerpop <- apply(fitmatpop, 1, quantile, prob=0.025)
newdat$upperpop <- apply(fitmatpop, 1, quantile, prob=0.975)
colkey <- colorRampPalette(c("orange", "blue"))(6)

par(mgp=c(2.5, 1, 0))
plot(ellenberg$Water, log(ellenberg$Yi.g),
     las=1, ylab=NA, type="n",
     xlab="Average distance to ground water (cm)", cex.lab=1.2)
mtext(expression(paste("Above-ground biomass ", (g/m^2),  " [log]")), 
      side=2, line=2.5, cex=1.2)
newdatpop <- newdat[1:100,]    
polygon(c(newdatpop$Water, rev(newdatpop$Water)), c(newdatpop$lowerpop, rev(newdatpop$upperpop)),
        border=NA, col=grey(0.6))
for(a in 1:6){
  index <- ellenberg$Species==levels(ellenberg$Species)[a]
  points(ellenberg$Water[index], log(ellenberg$Yi.g[index]), col=colkey[a], lwd=2, 
         pch=16, cex=0.6)
}

for(a in 1:6){
  index <- newdat$Species==levels(ellenberg$Species)[a]
  lines(newdat$Water[index], newdat$fit[index], col=colkey[a], lwd=2)
}

lines(newdatpop$Water, newdatpop$fitpop, lwd=3)
legend(-30, 9.4, bty="n", lwd=2, col=colkey, legend=levels(ellenberg$Species), 
       horiz=TRUE, xpd=NA, cex=0.9)
```

## Model selection in mixed models

Random effects are inexpensive in terms of degrees of freedom, because only one parameter per random effect is used. Further, natural processes vary on many different levels and, therefore, including random effects in a model leads to more realistic models in most cases. However, sometimes the model-fitting algorithms do not converge when the model is overloaded with random structures. Therefore, before adding a random effect to a model, be sure that the data contain some information about the specific variance parameter.

Sometimes, we would like to decide based on the data whether a random effect should be included in the model or not. This is model selection, and it is discussed in more detail in Chapter \@ref(model_comparison). However, when analyzing random factors, the following recommendations may be kept in mind: (1) As the random effects are estimated conditional on the fixed effects, model selection in the random part of the model should be done using a realistic fixed part of the model. This should include all possible predictors. (2) Random factors that are included because of the study design (e.g., subject of repeated measures, blocks) should, whenever possible, remain in the model. And (3) to get unbiased estimates for variance parameters (i.e., for the random effects) use REML.


## Further reading
The book by @Gelman.2007 is all about hierarchical models. @Pinheiro.2000 is the reference for fitting mixed models in R (and S). General guidelines to build a mixed model are given in @Verbeke.2000. @Zuur.2009 give a detailed example on model selection in mixed models.

Sometimes, covariates have different effects within and between groups of measurements. @vandePol.2009 present a simple method to distinguish such different effects using mixed models.

@McCulloch.2011 studied the effect of not normally distributed random effects in linear models and found that model predictions seem to be quite robust against the violation of the normal distribution assumption of random effects.

The wingbowl data set has been analyzed in detail in @Almasi.2012 taking into account that the corticosterone implant affects blood corticosterone concentration for only three days. The Ellenberg data set has been analyzed in detail, including also the effects of soil type and year, in @Hector.2012.
