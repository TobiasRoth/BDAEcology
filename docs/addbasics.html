<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Additional basic material | Bayesian Data Analysis in Ecology with R and Stan</title>
  <meta name="description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Additional basic material | Bayesian Data Analysis in Ecology with R and Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.jpg" />
  <meta property="og:description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="github-repo" content="TobiasRoth/BDAEcology" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Additional basic material | Bayesian Data Analysis in Ecology with R and Stan" />
  
  <meta name="twitter:description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="twitter:image" content="images/cover.jpg" />

<meta name="author" content="Fränzi Korner-Nievergelt, Tobias Roth, Stefanie von Felten, Jerôme Guélat, Bettina Almasi, Pius Korner-Nievergelt" />


<meta name="date" content="2021-02-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="distributions.html"/>
<link rel="next" href="furthertopics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="settings/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i>Why this book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-contribute"><i class="fa fa-check"></i>How to contribute?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="part"><span><b>I R FOR ECOLOGISTS</b></span></li>
<li class="chapter" data-level="1" data-path="PART-I.html"><a href="PART-I.html"><i class="fa fa-check"></i><b>1</b> Introduction to PART I</a><ul>
<li class="chapter" data-level="1.1" data-path="PART-I.html"><a href="PART-I.html#further-reading"><i class="fa fa-check"></i><b>1.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>2</b> Prerequisits: Basic statistical terms</a><ul>
<li class="chapter" data-level="2.1" data-path="basics.html"><a href="basics.html#variables-and-observations"><i class="fa fa-check"></i><b>2.1</b> Variables and observations</a></li>
<li class="chapter" data-level="2.2" data-path="basics.html"><a href="basics.html#displaying-and-summarizing-variables"><i class="fa fa-check"></i><b>2.2</b> Displaying and summarizing variables</a><ul>
<li class="chapter" data-level="2.2.1" data-path="basics.html"><a href="basics.html#correlations"><i class="fa fa-check"></i><b>2.2.1</b> Correlations</a></li>
<li class="chapter" data-level="2.2.2" data-path="basics.html"><a href="basics.html#principal-components-analyses-pca"><i class="fa fa-check"></i><b>2.2.2</b> Principal components analyses PCA</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="basics.html"><a href="basics.html#inferential-statistics"><i class="fa fa-check"></i><b>2.3</b> Inferential statistics</a><ul>
<li class="chapter" data-level="2.3.1" data-path="basics.html"><a href="basics.html#uncertainty"><i class="fa fa-check"></i><b>2.3.1</b> Uncertainty</a></li>
<li class="chapter" data-level="2.3.2" data-path="basics.html"><a href="basics.html#standard-error"><i class="fa fa-check"></i><b>2.3.2</b> Standard error</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="basics.html"><a href="basics.html#bayes-theorem-and-the-common-aim-of-frequentist-and-bayesian-methods"><i class="fa fa-check"></i><b>2.4</b> Bayes theorem and the common aim of frequentist and Bayesian methods</a><ul>
<li class="chapter" data-level="2.4.1" data-path="basics.html"><a href="basics.html#bayes-theorem-for-discrete-events"><i class="fa fa-check"></i><b>2.4.1</b> Bayes theorem for discrete events</a></li>
<li class="chapter" data-level="2.4.2" data-path="basics.html"><a href="basics.html#bayes-theorem-for-continuous-parameters"><i class="fa fa-check"></i><b>2.4.2</b> Bayes theorem for continuous parameters</a></li>
<li class="chapter" data-level="2.4.3" data-path="basics.html"><a href="basics.html#estimating-a-mean-assuming-that-the-variance-is-known"><i class="fa fa-check"></i><b>2.4.3</b> Estimating a mean assuming that the variance is known</a></li>
<li class="chapter" data-level="2.4.4" data-path="basics.html"><a href="basics.html#estimating-the-mean-and-the-variance"><i class="fa fa-check"></i><b>2.4.4</b> Estimating the mean and the variance</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="basics.html"><a href="basics.html#classical-frequentist-tests-and-alternatives"><i class="fa fa-check"></i><b>2.5</b> Classical frequentist tests and alternatives</a><ul>
<li class="chapter" data-level="2.5.1" data-path="basics.html"><a href="basics.html#nullhypothesis-testing"><i class="fa fa-check"></i><b>2.5.1</b> Nullhypothesis testing</a></li>
<li class="chapter" data-level="2.5.2" data-path="basics.html"><a href="basics.html#comparison-of-a-sample-with-a-fixed-values-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.2</b> Comparison of a sample with a fixed values (one-sample t-test)</a></li>
<li class="chapter" data-level="2.5.3" data-path="basics.html"><a href="basics.html#comparison-of-the-locations-between-two-groups-two-sample-t-test"><i class="fa fa-check"></i><b>2.5.3</b> Comparison of the locations between two groups (two-sample t-test)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="basics.html"><a href="basics.html#summary"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analyses-steps.html"><a href="analyses-steps.html"><i class="fa fa-check"></i><b>3</b> Data analysis step by step</a><ul>
<li class="chapter" data-level="3.1" data-path="analyses-steps.html"><a href="analyses-steps.html#step1"><i class="fa fa-check"></i><b>3.1</b> Plausibility of Data</a></li>
<li class="chapter" data-level="3.2" data-path="analyses-steps.html"><a href="analyses-steps.html#step2"><i class="fa fa-check"></i><b>3.2</b> Relationships</a></li>
<li class="chapter" data-level="3.3" data-path="analyses-steps.html"><a href="analyses-steps.html#step3"><i class="fa fa-check"></i><b>3.3</b> Data Distribution</a></li>
<li class="chapter" data-level="3.4" data-path="analyses-steps.html"><a href="analyses-steps.html#step4"><i class="fa fa-check"></i><b>3.4</b> Preparation of Explanatory Variables</a></li>
<li class="chapter" data-level="3.5" data-path="analyses-steps.html"><a href="analyses-steps.html#step5"><i class="fa fa-check"></i><b>3.5</b> Data Structure</a></li>
<li class="chapter" data-level="3.6" data-path="analyses-steps.html"><a href="analyses-steps.html#step6"><i class="fa fa-check"></i><b>3.6</b> Define Prior Distributions</a></li>
<li class="chapter" data-level="3.7" data-path="analyses-steps.html"><a href="analyses-steps.html#step7"><i class="fa fa-check"></i><b>3.7</b> Fit the Model</a></li>
<li class="chapter" data-level="3.8" data-path="analyses-steps.html"><a href="analyses-steps.html#step8"><i class="fa fa-check"></i><b>3.8</b> Check Model</a></li>
<li class="chapter" data-level="3.9" data-path="analyses-steps.html"><a href="analyses-steps.html#step9"><i class="fa fa-check"></i><b>3.9</b> Model Uncertainty</a></li>
<li class="chapter" data-level="3.10" data-path="analyses-steps.html"><a href="analyses-steps.html#step10"><i class="fa fa-check"></i><b>3.10</b> Draw Conclusions</a></li>
<li class="chapter" data-level="" data-path="analyses-steps.html"><a href="analyses-steps.html#further-reading-1"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>4</b> Probability distributions</a><ul>
<li class="chapter" data-level="4.1" data-path="distributions.html"><a href="distributions.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>4.2</b> Normal distribution</a></li>
<li class="chapter" data-level="4.3" data-path="distributions.html"><a href="distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>4.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="4.4" data-path="distributions.html"><a href="distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>4.4</b> Gamma distribution</a><ul>
<li class="chapter" data-level="4.4.1" data-path="distributions.html"><a href="distributions.html#cauchydistri"><i class="fa fa-check"></i><b>4.4.1</b> Cauchy distribution</a></li>
<li class="chapter" data-level="4.4.2" data-path="distributions.html"><a href="distributions.html#t-distribution"><i class="fa fa-check"></i><b>4.4.2</b> t-distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distributions.html"><a href="distributions.html#f-distribution"><i class="fa fa-check"></i><b>4.5</b> F-distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="addbasics.html"><a href="addbasics.html"><i class="fa fa-check"></i><b>5</b> Additional basic material</a><ul>
<li class="chapter" data-level="5.1" data-path="addbasics.html"><a href="addbasics.html#chisquare-test"><i class="fa fa-check"></i><b>5.1</b> Chisquare test</a></li>
<li class="chapter" data-level="5.2" data-path="addbasics.html"><a href="addbasics.html#methods-for-getting-the-posterior-distribution"><i class="fa fa-check"></i><b>5.2</b> 3 methods for getting the posterior distribution</a><ul>
<li class="chapter" data-level="5.2.1" data-path="addbasics.html"><a href="addbasics.html#monte-carlo-simulation-parametric-bootstrap"><i class="fa fa-check"></i><b>5.2.1</b> Monte Carlo simulation (parametric bootstrap)</a></li>
<li class="chapter" data-level="5.2.2" data-path="addbasics.html"><a href="addbasics.html#grid-approximation"><i class="fa fa-check"></i><b>5.2.2</b> Grid approximation</a></li>
<li class="chapter" data-level="5.2.3" data-path="addbasics.html"><a href="addbasics.html#markov-chain-monte-carlo-simulations"><i class="fa fa-check"></i><b>5.2.3</b> Markov chain Monte Carlo simulations</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="addbasics.html"><a href="addbasics.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.3</b> Analysis of variance ANOVA</a></li>
<li class="chapter" data-level="5.4" data-path="addbasics.html"><a href="addbasics.html#bayesian-way-of-analysing-correlations-between-categorical-variables"><i class="fa fa-check"></i><b>5.4</b> Bayesian way of analysing correlations between categorical variables</a></li>
<li class="chapter" data-level="5.5" data-path="addbasics.html"><a href="addbasics.html#summary-1"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="furthertopics.html"><a href="furthertopics.html"><i class="fa fa-check"></i><b>6</b> Further topics</a><ul>
<li class="chapter" data-level="6.1" data-path="furthertopics.html"><a href="furthertopics.html#bioacoustic-analyse"><i class="fa fa-check"></i><b>6.1</b> Bioacoustic analyse</a></li>
<li class="chapter" data-level="6.2" data-path="furthertopics.html"><a href="furthertopics.html#python"><i class="fa fa-check"></i><b>6.2</b> Python</a></li>
</ul></li>
<li class="part"><span><b>II BAYESIAN DATA ANALYSIS</b></span></li>
<li class="chapter" data-level="7" data-path="PART-II.html"><a href="PART-II.html"><i class="fa fa-check"></i><b>7</b> Introduction to PART II</a><ul>
<li class="chapter" data-level="" data-path="PART-II.html"><a href="PART-II.html#further-reading-2"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>8</b> MCMC using Stan</a><ul>
<li class="chapter" data-level="8.1" data-path="stan.html"><a href="stan.html#background"><i class="fa fa-check"></i><b>8.1</b> Background</a></li>
<li class="chapter" data-level="8.2" data-path="stan.html"><a href="stan.html#install-rstan"><i class="fa fa-check"></i><b>8.2</b> Install <code>rstan</code></a></li>
<li class="chapter" data-level="8.3" data-path="stan.html"><a href="stan.html#firststanmod"><i class="fa fa-check"></i><b>8.3</b> Writing a Stan model</a></li>
<li class="chapter" data-level="8.4" data-path="stan.html"><a href="stan.html#run-stan-from-r"><i class="fa fa-check"></i><b>8.4</b> Run Stan from R</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#further-reading-3"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>9</b> Prior distributions</a><ul>
<li class="chapter" data-level="9.1" data-path="priors.html"><a href="priors.html#introduction-1"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="priors.html"><a href="priors.html#choosepriors"><i class="fa fa-check"></i><b>9.2</b> How to choose a prior</a></li>
<li class="chapter" data-level="9.3" data-path="priors.html"><a href="priors.html#prior-sensitivity"><i class="fa fa-check"></i><b>9.3</b> Prior sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>10</b> Normal Linear Models</a><ul>
<li class="chapter" data-level="10.1" data-path="lm.html"><a href="lm.html#linear-regression"><i class="fa fa-check"></i><b>10.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="lm.html"><a href="lm.html#background-1"><i class="fa fa-check"></i><b>10.1.1</b> Background</a></li>
<li class="chapter" data-level="10.1.2" data-path="lm.html"><a href="lm.html#fitting-a-linear-regression-in-r"><i class="fa fa-check"></i><b>10.1.2</b> Fitting a Linear Regression in R</a></li>
<li class="chapter" data-level="10.1.3" data-path="lm.html"><a href="lm.html#drawing-conclusions"><i class="fa fa-check"></i><b>10.1.3</b> Drawing Conclusions</a></li>
<li class="chapter" data-level="10.1.4" data-path="lm.html"><a href="lm.html#frequentist-results"><i class="fa fa-check"></i><b>10.1.4</b> Frequentist Results</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="lm.html"><a href="lm.html#regression-variants-anova-ancova-and-multiple-regression"><i class="fa fa-check"></i><b>10.2</b> Regression Variants: ANOVA, ANCOVA, and Multiple Regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="lm.html"><a href="lm.html#one-way-anova"><i class="fa fa-check"></i><b>10.2.1</b> One-Way ANOVA</a></li>
<li class="chapter" data-level="10.2.2" data-path="lm.html"><a href="lm.html#frequentist-results-from-a-one-way-anova"><i class="fa fa-check"></i><b>10.2.2</b> Frequentist Results from a One-Way ANOVA</a></li>
<li class="chapter" data-level="10.2.3" data-path="lm.html"><a href="lm.html#two-way-anova"><i class="fa fa-check"></i><b>10.2.3</b> Two-Way ANOVA</a></li>
<li class="chapter" data-level="10.2.4" data-path="lm.html"><a href="lm.html#frequentist-results-from-a-two-way-anova"><i class="fa fa-check"></i><b>10.2.4</b> Frequentist Results from a Two-Way ANOVA</a></li>
<li class="chapter" data-level="10.2.5" data-path="lm.html"><a href="lm.html#multiple-comparisons-and-post-hoc-tests"><i class="fa fa-check"></i><b>10.2.5</b> Multiple Comparisons and Post Hoc Tests</a></li>
<li class="chapter" data-level="10.2.6" data-path="lm.html"><a href="lm.html#analysis-of-covariance"><i class="fa fa-check"></i><b>10.2.6</b> Analysis of Covariance</a></li>
<li class="chapter" data-level="10.2.7" data-path="lm.html"><a href="lm.html#multiple-regression-and-collinearity"><i class="fa fa-check"></i><b>10.2.7</b> Multiple Regression and Collinearity</a></li>
<li class="chapter" data-level="10.2.8" data-path="lm.html"><a href="lm.html#orderedfactors"><i class="fa fa-check"></i><b>10.2.8</b> Ordered Factors and Contrasts</a></li>
<li class="chapter" data-level="10.2.9" data-path="lm.html"><a href="lm.html#quadratic-and-higher-polynomial-terms"><i class="fa fa-check"></i><b>10.2.9</b> Quadratic and Higher Polynomial Terms</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="lm.html"><a href="lm.html#pendenzen"><i class="fa fa-check"></i><b>10.3</b> Pendenzen</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="residualanalysis.html"><a href="residualanalysis.html"><i class="fa fa-check"></i><b>11</b> Assessing Model Assumptions</a><ul>
<li class="chapter" data-level="11.1" data-path="residualanalysis.html"><a href="residualanalysis.html#model-assumptions"><i class="fa fa-check"></i><b>11.1</b> Model Assumptions</a></li>
<li class="chapter" data-level="11.2" data-path="residualanalysis.html"><a href="residualanalysis.html#independent-and-identically-distributed"><i class="fa fa-check"></i><b>11.2</b> Independent and Identically Distributed</a></li>
<li class="chapter" data-level="11.3" data-path="residualanalysis.html"><a href="residualanalysis.html#qqplot"><i class="fa fa-check"></i><b>11.3</b> The QQ-Plot</a></li>
<li class="chapter" data-level="11.4" data-path="residualanalysis.html"><a href="residualanalysis.html#tempautocorrelation"><i class="fa fa-check"></i><b>11.4</b> Temporal Autocorrelation</a></li>
<li class="chapter" data-level="11.5" data-path="residualanalysis.html"><a href="residualanalysis.html#spatialautocorrelation"><i class="fa fa-check"></i><b>11.5</b> Spatial Autocorrelation</a></li>
<li class="chapter" data-level="11.6" data-path="residualanalysis.html"><a href="residualanalysis.html#Heteroscedasticity"><i class="fa fa-check"></i><b>11.6</b> Heteroscedasticity</a></li>
</ul></li>
<li class="part"><span><b>III ECOLOGICAL MODELS</b></span></li>
<li class="chapter" data-level="12" data-path="PART-III.html"><a href="PART-III.html"><i class="fa fa-check"></i><b>12</b> Introduction to PART III</a><ul>
<li class="chapter" data-level="12.1" data-path="PART-III.html"><a href="PART-III.html#model-notations"><i class="fa fa-check"></i><b>12.1</b> Model notations</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html"><i class="fa fa-check"></i><b>13</b> Zero-inflated Poisson Mixed Model</a><ul>
<li class="chapter" data-level="13.1" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#introduction-2"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#example-data"><i class="fa fa-check"></i><b>13.2</b> Example data</a></li>
<li class="chapter" data-level="13.3" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#model"><i class="fa fa-check"></i><b>13.3</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="dailynestsurv.html"><a href="dailynestsurv.html"><i class="fa fa-check"></i><b>14</b> Daily nest survival</a><ul>
<li class="chapter" data-level="14.1" data-path="dailynestsurv.html"><a href="dailynestsurv.html#background-2"><i class="fa fa-check"></i><b>14.1</b> Background</a></li>
<li class="chapter" data-level="14.2" data-path="dailynestsurv.html"><a href="dailynestsurv.html#models-for-estimating-daily-nest-survival"><i class="fa fa-check"></i><b>14.2</b> Models for estimating daily nest survival</a></li>
<li class="chapter" data-level="14.3" data-path="dailynestsurv.html"><a href="dailynestsurv.html#known-fate-model"><i class="fa fa-check"></i><b>14.3</b> Known fate model</a></li>
<li class="chapter" data-level="14.4" data-path="dailynestsurv.html"><a href="dailynestsurv.html#dailynestsurvstan"><i class="fa fa-check"></i><b>14.4</b> The Stan model</a></li>
<li class="chapter" data-level="14.5" data-path="dailynestsurv.html"><a href="dailynestsurv.html#prepare-data-and-run-stan"><i class="fa fa-check"></i><b>14.5</b> Prepare data and run Stan</a></li>
<li class="chapter" data-level="14.6" data-path="dailynestsurv.html"><a href="dailynestsurv.html#check-convergence"><i class="fa fa-check"></i><b>14.6</b> Check convergence</a></li>
<li class="chapter" data-level="14.7" data-path="dailynestsurv.html"><a href="dailynestsurv.html#look-at-results"><i class="fa fa-check"></i><b>14.7</b> Look at results</a></li>
<li class="chapter" data-level="14.8" data-path="dailynestsurv.html"><a href="dailynestsurv.html#known-fate-model-for-irregular-nest-controls"><i class="fa fa-check"></i><b>14.8</b> Known fate model for irregular nest controls</a></li>
<li class="chapter" data-level="" data-path="dailynestsurv.html"><a href="dailynestsurv.html#further-reading-4"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html"><i class="fa fa-check"></i><b>15</b> Capture-mark recapture model with a mixture structure to account for missing sex-variable for parts of the individuals</a><ul>
<li class="chapter" data-level="15.1" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#introduction-3"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#data-description"><i class="fa fa-check"></i><b>15.2</b> Data description</a></li>
<li class="chapter" data-level="15.3" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#model-description"><i class="fa fa-check"></i><b>15.3</b> Model description</a></li>
<li class="chapter" data-level="15.4" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#the-stan-code"><i class="fa fa-check"></i><b>15.4</b> The Stan code</a></li>
<li class="chapter" data-level="15.5" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#call-stan-from-r-check-convergence-and-look-at-results"><i class="fa fa-check"></i><b>15.5</b> Call Stan from R, check convergence and look at results</a></li>
</ul></li>
<li class="part"><span><b>IV APPENDICES</b></span></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
<li class="divider"></li>
</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Data Analysis in Ecology with R and Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="addbasics" class="section level1">
<h1><span class="header-section-number">5</span> Additional basic material</h1>
<p>THIS CHAPTER IS UNDER CONSTRUCTION!!!</p>
<div id="chisquare-test" class="section level2">
<h2><span class="header-section-number">5.1</span> Chisquare test</h2>
<p>The chisquare test is used for two frequentist purposes.<br />
1. Testing for correlations between two categorical variables.<br />
2. Comparison of two distributions (goodness of fit test)</p>
<p>When testing for correlations between two categorical variables, then the nullhypothesis is “there is no correlation”. The data can be displayed in cross-tables.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="addbasics.html#cb40-1"></a><span class="co"># Example: correlation between birthday preference and car ownership</span></span>
<span id="cb40-2"><a href="addbasics.html#cb40-2"></a><span class="kw">load</span>(<span class="st">&quot;RData/datacourse.RData&quot;</span>)</span>
<span id="cb40-3"><a href="addbasics.html#cb40-3"></a><span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car)</span></code></pre></div>
<pre><code>##          
##           N Y
##   flowers 6 1
##   wine    9 6</code></pre>
<p>Given the nullhypothesis is true, we expect that the distribution of the data in each column of the cross-table is similar to the distribution of the row-sums. And, the distribution of the data in each row should be similar to the distribution of the column-sums. The chisquare test statistics <span class="math inline">\(\chi^2\)</span> measures the deviation of the data from this expected distribution of the data in the cross-table.</p>
<p>For calculating the chisquare test statistics <span class="math inline">\(\chi^2\)</span>, we first have to obtain for each cell in the cross-table the expected value <span class="math inline">\(E_{ij}\)</span> = rowsum*colsum/total.</p>
<p><span class="math inline">\(\chi^2\)</span> measures the difference between the observed <span class="math inline">\(O_{ij}\)</span> and expected <span class="math inline">\(E_{ij}\)</span> values as:<br />
<span class="math inline">\(\chi^2=\sum_{i=1}^{m}\sum_{j=1}^{k}\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\)</span> where <span class="math inline">\(m\)</span> is the number of rows and <span class="math inline">\(k\)</span> is the number of columns.
The <span class="math inline">\(\chi^2\)</span>-distribution has 1 parameter, the degrees of freedom <span class="math inline">\(v\)</span> = <span class="math inline">\((m-1)(k-1)\)</span>.</p>
<p><img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>R is calculating the <span class="math inline">\(\chi^2\)</span> value for specific cross-tables, and it is also giving the p-values, i.e., the probability of obtaining the observed or a higher <span class="math inline">\(\chi^2\)</span> value given the nullhypothesis is true by comparing the observed <span class="math inline">\(\chi^2\)</span> with the corresponding chisquare distribution.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="addbasics.html#cb42-1"></a><span class="kw">chisq.test</span>(<span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car))</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(dat$birthday, dat$car)
## X-squared = 0.51084, df = 1, p-value = 0.4748</code></pre>
<p>The warning (that is suppressed in the rmarkdown version, but that you will see if you run the code on your own computer) is given, because in our example some cells have counts less than 5. In such cases, the Fisher’s exact test should be preferred. This test calculates the p-value analytically using probability theory, whereas the chisquare test relies on the assumption that the <span class="math inline">\(\chi^2\)</span> value follows a chisquare distribution. The latter assumption holds better for larger sample sizes.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="addbasics.html#cb44-1"></a><span class="kw">fisher.test</span>(<span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car))</span></code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  table(dat$birthday, dat$car)
## p-value = 0.3501
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##    0.3153576 213.8457248
## sample estimates:
## odds ratio 
##   3.778328</code></pre>
</div>
<div id="methods-for-getting-the-posterior-distribution" class="section level2">
<h2><span class="header-section-number">5.2</span> 3 methods for getting the posterior distribution</h2>
<ul>
<li>analytically</li>
<li>approximation</li>
<li>Monte Carlo simulation</li>
</ul>
<div id="monte-carlo-simulation-parametric-bootstrap" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Monte Carlo simulation (parametric bootstrap)</h3>
<p>Monte Carlo integration: numerical solution of <span class="math inline">\(\int_{-1}^{1.5} F(x) dx\)</span>
<img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>sim is solving a mathematical problem by simulation
How sim is simulating to get the marginal distribution of <span class="math inline">\(\mu\)</span>:</p>
<p><img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="grid-approximation" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Grid approximation</h3>
<p><span class="math inline">\(p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}\)</span></p>
<p>For example, one coin flip (Bernoulli model)</p>
<p>data: y=0 (a tail)<br />
likelihood: <span class="math inline">\(p(y|\theta)=\theta^y(1-\theta)^{(1-y)}\)</span></p>
<p><img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="markov-chain-monte-carlo-simulations" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Markov chain Monte Carlo simulations</h3>
<ul>
<li>Markov chain Monte Carlo simulation (BUGS, Jags)</li>
<li>Hamiltonian Monte Carlo (Stan)</li>
</ul>
<p><img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
</div>
<div id="analysis-of-variance-anova" class="section level2">
<h2><span class="header-section-number">5.3</span> Analysis of variance ANOVA</h2>
<p>The aim of an ANOVA is to compare means of groups. In a frequentist analysis, this is done by comparing the between-group with the within-group variance. The result of a Bayesian analysis is the joint posterior distribution of the group means.</p>
<div class="figure"><span id="fig:unnamed-chunk-9"></span>
<img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-9-1.png" alt="Number of stats courses students have taken before starting a PhD in relation to their feeling about statistics." width="672" />
<p class="caption">
Figure 5.1: Number of stats courses students have taken before starting a PhD in relation to their feeling about statistics.
</p>
</div>
<p>In the frequentist ANOVA, the following three sum of squared distances (SS) are used to calculate the total, the between- and within-group variances:<br />
Total sum of squares = SST = <span class="math inline">\(\sum_1^n{(y_i-\bar{y})^2}\)</span><br />
Within-group SS = SSW = <span class="math inline">\(\sum_1^n{(y_i-\bar{y_g})^2}\)</span>: unexplained variance<br />
Between-group SS = SSB = <span class="math inline">\(\sum_1^g{n_g(\bar{y_g}-\bar{y})^2}\)</span>: explained variance</p>
<p>The between-group and within-group SS sum to the total sum of squares: SST=SSB+SSW. Attention: this equation is only true in any case for a simple one-way ANOVA (just one grouping factor). If the data are grouped according to more than one factor (such as in a two- or three-way ANOVA), then there is one single solution for the equation only when the data is completely balanced, i.e. when there are the same number of observations in all combinations of factor levels. For non-balanced data with more than one grouping factor, there are different ways of calculating the SSBs, and the result of the F-test described below depends on the order of the predictors in the model.</p>
<div class="figure"><span id="fig:unnamed-chunk-10"></span>
<img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-10-1.png" alt="Visualisation of the total, between-group and within-group sum of squares. Points are observations; long horizontal line is the overall mean; short horizontal lines are group specific means." width="672" />
<p class="caption">
Figure 5.2: Visualisation of the total, between-group and within-group sum of squares. Points are observations; long horizontal line is the overall mean; short horizontal lines are group specific means.
</p>
</div>
<p>In order to make SSB and SSW comparable, we have to divide them by their degrees of freedoms. For the within-group SS, SSW, the degrees of freedom is the number of obervations minus the number of groups (<span class="math inline">\(g\)</span>), because <span class="math inline">\(g\)</span> means have been estimated from the data. If the <span class="math inline">\(g\)</span> means are fixed and <span class="math inline">\(n-g\)</span> data points are known, then the last <span class="math inline">\(g\)</span> data points are defined, i.e., they cannot be chosen freely. For the between-group SS, SSB, the degrees of freedom is the number of groups minus 1 (the minus 1 stands for the overall mean).</p>
<ul>
<li>MSB = SSB/df_between, MSW = SSW/df_within</li>
</ul>
<p>It can be shown (by mathematicians) that, given the nullhypothesis, the mean of all groups are equal <span class="math inline">\(m_1 = m_2 = m_3\)</span>, then the mean squared errors between groups (MSB) is expected to be equal to the mean squared errors within the groups (MSW). Therefore, the ration MSB/MSW is expected to follow an F-distribution given the nullhypothesis is true.</p>
<ul>
<li>MSB/MSW ~ F(df_between, df_within)</li>
</ul>
<p>The Bayesian analysis for comparing group means consists of calculating the posterior distribution for each group mean and then drawing inference from these posterior distributions.
A Bayesian one-way ANOVA involves the following steps:<br />
1. Decide for a data model: We, here, assume that the measurements are normally distributed around the group means. In this example here, we transform the outcome variable in order to better meet the normal assumption. Note: the frequentist ANOVA makes exactly the same assumptions. We can write the data model: <span class="math inline">\(y_i\sim Norm(\mu_i,\sigma)\)</span> with <span class="math inline">\(mu_i= \beta_0 + \beta_1I(group=2) +\beta_1I(group=3)\)</span>, where the <span class="math inline">\(I()\)</span>-function is an indicator function taking on 1 if the expression is true and 0 otherwise. This model has 4 parameters: <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="addbasics.html#cb46-1"></a><span class="co"># fit a normal model with 3 different means</span></span>
<span id="cb46-2"><a href="addbasics.html#cb46-2"></a>mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(nrcourses<span class="op">+</span><span class="dv">1</span>)<span class="op">~</span>statsfeeling, <span class="dt">data=</span>dat)</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><p>Choose a prior distribution for each model parameter: In this example, we choose flat prior distributions for each parameter. By using these priors, the result should not remarkably be affected by the prior distributions but almost only reflect the information in the data. We choose so-called improper prior distributions. These are completely flat distributions that give all parameter values the same probability. Such distributions are called improper because the area under the curve is not summing to 1 and therefore, they cannot be considered to be proper probability distributions. However, they can still be used to solve the Bayesian theorem.</p></li>
<li><p>Solve the Bayes theorem: The solution of the Bayes theorem for the above priors and model is implemented in the function sim of the package arm.</p></li>
</ol>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="addbasics.html#cb47-1"></a><span class="co"># calculate numerically the posterior distributions of the model </span></span>
<span id="cb47-2"><a href="addbasics.html#cb47-2"></a><span class="co"># parameters using flat prior distributions</span></span>
<span id="cb47-3"><a href="addbasics.html#cb47-3"></a>nsim &lt;-<span class="st"> </span><span class="dv">5000</span></span>
<span id="cb47-4"><a href="addbasics.html#cb47-4"></a><span class="kw">set.seed</span>(<span class="dv">346346</span>)</span>
<span id="cb47-5"><a href="addbasics.html#cb47-5"></a>bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Display the joint posterior distributions of the group means</li>
</ol>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="addbasics.html#cb48-1"></a><span class="co"># calculate group means from the model parameters</span></span>
<span id="cb48-2"><a href="addbasics.html#cb48-2"></a>newdat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">statsfeeling=</span><span class="kw">levels</span>(<span class="kw">factor</span>(dat<span class="op">$</span>statsfeeling)))</span>
<span id="cb48-3"><a href="addbasics.html#cb48-3"></a>X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span>statsfeeling, <span class="dt">data=</span>newdat)</span>
<span id="cb48-4"><a href="addbasics.html#cb48-4"></a>fitmat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol=</span>nsim, <span class="dt">nrow=</span><span class="kw">nrow</span>(newdat))</span>
<span id="cb48-5"><a href="addbasics.html#cb48-5"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim) fitmat[,i] &lt;-<span class="st"> </span>X<span class="op">%*%</span>bsim<span class="op">@</span>coef[i,]</span>
<span id="cb48-6"><a href="addbasics.html#cb48-6"></a><span class="kw">hist</span>(fitmat[<span class="dv">1</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;Group mean of log(number of courses +1)&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">2.2</span>))</span>
<span id="cb48-7"><a href="addbasics.html#cb48-7"></a><span class="kw">hist</span>(fitmat[<span class="dv">2</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.5</span>))</span>
<span id="cb48-8"><a href="addbasics.html#cb48-8"></a><span class="kw">hist</span>(fitmat[<span class="dv">3</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))</span>
<span id="cb48-9"><a href="addbasics.html#cb48-9"></a><span class="kw">legend</span>(<span class="dv">2</span>,<span class="dv">2</span>, <span class="dt">fill=</span><span class="kw">c</span>(<span class="st">&quot;white&quot;</span>,<span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.5</span>), <span class="kw">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>)), <span class="dt">legend=</span><span class="kw">levels</span>(<span class="kw">factor</span>(dat<span class="op">$</span>statsfeeling)))</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-13"></span>
<img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-13-1.png" alt="Posterior distributions of the mean number of stats courses PhD students visited before starting the PhD grouped according to their feelings about statistics." width="672" />
<p class="caption">
Figure 5.3: Posterior distributions of the mean number of stats courses PhD students visited before starting the PhD grouped according to their feelings about statistics.
</p>
</div>
<p>Based on the posterior distributions of the group means, we can extract derived quantities depending on our interest and questions. Here, for example, we could extract the posterior probability of the hypothesis that students with a positive feeling about statistics have a better education in statistics than those with a neutral or negative feeling about statistics.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="addbasics.html#cb49-1"></a><span class="co"># P(mean(positive)&gt;mean(neutral))</span></span>
<span id="cb49-2"><a href="addbasics.html#cb49-2"></a><span class="kw">mean</span>(fitmat[<span class="dv">3</span>,]<span class="op">&gt;</span>fitmat[<span class="dv">2</span>,])</span></code></pre></div>
<pre><code>## [1] 0.8754</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="addbasics.html#cb51-1"></a><span class="co"># P(mean(positive)&gt;mean(negative))</span></span>
<span id="cb51-2"><a href="addbasics.html#cb51-2"></a><span class="kw">mean</span>(fitmat[<span class="dv">3</span>,]<span class="op">&gt;</span>fitmat[<span class="dv">1</span>,])</span></code></pre></div>
<pre><code>## [1] 0.9798</code></pre>
</div>
<div id="bayesian-way-of-analysing-correlations-between-categorical-variables" class="section level2">
<h2><span class="header-section-number">5.4</span> Bayesian way of analysing correlations between categorical variables</h2>
<p>For a Bayesian analysis of cross-table data, a data model has to be found. There are several possibilities that could be used:</p>
<ul>
<li>a so-called log-linear model (Poisson model) for the counts in each cell of the cross-table.<br />
</li>
<li>a binomial or a multinomial model for obtaining estimates of the proportions of data in each cell</li>
</ul>
<p>These models provide possibilities to explore the patterns in the data in more details than a chisquare test.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="addbasics.html#cb53-1"></a><span class="co"># log-linear model</span></span>
<span id="cb53-2"><a href="addbasics.html#cb53-2"></a>mod &lt;-<span class="st"> </span><span class="kw">glm</span>(count<span class="op">~</span>birthday<span class="op">+</span>car <span class="op">+</span><span class="st"> </span>birthday<span class="op">:</span>car, </span>
<span id="cb53-3"><a href="addbasics.html#cb53-3"></a>           <span class="dt">data=</span>datagg, <span class="dt">family=</span>poisson)</span>
<span id="cb53-4"><a href="addbasics.html#cb53-4"></a>bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)</span>
<span id="cb53-5"><a href="addbasics.html#cb53-5"></a><span class="kw">round</span>(<span class="kw">t</span>(<span class="kw">apply</span>(bsim<span class="op">@</span>coef, <span class="dv">2</span>, quantile, </span>
<span id="cb53-6"><a href="addbasics.html#cb53-6"></a>              <span class="dt">prob=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))),<span class="dv">2</span>)</span></code></pre></div>
<pre><code>##                    2.5%   50% 97.5%
## (Intercept)        0.99  1.79  2.58
## birthdaywine      -0.60  0.41  1.43
## carY              -3.89 -1.77  0.29
## birthdaywine:carY -0.94  1.38  3.65</code></pre>
<p>The interaction parameter measures the strength of the correlation. To quantitatively understand what a parameter value of 1.39 means, we have to look at the interpretation of all parameter values. We do that here quickly without a thorough explanation, because we already explained the Poisson model in chapter 8 of <span class="citation">(Korner-Nievergelt et al. <a href="referenzen.html#ref-KornerNievergelt2015" role="doc-biblioref">2015</a>)</span>.</p>
<p>The intercept 1.79 corresponds to the logarithm of the count in the cell “flowers” and “N” (number of students who prefer flowers as a birthday present and who do not have a car), i.e., <span class="math inline">\(exp(\beta_0)\)</span> = 6. The exponent of the second parameter corresponds to the multiplicative difference between the counts in the cells “flowers and N” and “wine and N”, i.e., count in the cell “wine and N” = <span class="math inline">\(exp(\beta_0)exp(\beta_1)\)</span> = exp(1.79)exp(0.41) = 9. The third parameter measures the multiplicative difference in the counts between the cells “flowers and N” and “flowers and Y”, i.e., count in the cell “flowers and Y” = <span class="math inline">\(exp(\beta_0)exp(\beta_2)\)</span> = exp(1.79)exp(-1.79) = 1. Thus, the third parameter is the difference in the logarithm of the counts between the car owners and the car-free students for those who prefer flowers. The interaction parameter is the difference of this difference between the students who prefer wine and those who prefer flowers. This is difficult to intuitively understand. Here is another try to formulate it: The interaction parameter measures the difference in the logarithm of the counts in the cross-table between the row-differences between the columns. Maybe it becomes clear, when we extract the count in the cell “wine and Y” from the model parameters: <span class="math inline">\(exp(\beta_0)exp(\beta_1)exp(\beta_2)exp(\beta_3)\)</span> = exp(1.79)exp(0.41)exp(-1.79)exp(1.39) = 6.</p>
<p>Alternatively, we could estimate the proportions of flower and wine preferers within each group of car owners and car-free students using a binomial model. For an explanation of the binomial model, see chapter 8 of <span class="citation">(Korner-Nievergelt et al. <a href="referenzen.html#ref-KornerNievergelt2015" role="doc-biblioref">2015</a>)</span>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="addbasics.html#cb55-1"></a><span class="co"># binomial model</span></span>
<span id="cb55-2"><a href="addbasics.html#cb55-2"></a>tab &lt;-<span class="st"> </span><span class="kw">table</span>(dat<span class="op">$</span>car,dat<span class="op">$</span>birthday)</span>
<span id="cb55-3"><a href="addbasics.html#cb55-3"></a>mod &lt;-<span class="st"> </span><span class="kw">glm</span>(tab<span class="op">~</span><span class="kw">rownames</span>(tab),  <span class="dt">family=</span>binomial)</span>
<span id="cb55-4"><a href="addbasics.html#cb55-4"></a>bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-18"></span>
<img src="1.4-additional_basic_material_files/figure-html/unnamed-chunk-18-1.png" alt="Estimated proportion of students that prefer flowers over wine as a birthday present among the car-free students (N) and the car owners (Y). Given are the median of the posterior distribution (circle). The bar extends between the 2.5% and 97.5% quantiles of the posterior distribution." width="672" />
<p class="caption">
Figure 5.4: Estimated proportion of students that prefer flowers over wine as a birthday present among the car-free students (N) and the car owners (Y). Given are the median of the posterior distribution (circle). The bar extends between the 2.5% and 97.5% quantiles of the posterior distribution.
</p>
</div>
</div>
<div id="summary-1" class="section level2">
<h2><span class="header-section-number">5.5</span> Summary</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="furthertopics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/TobiasRoth/BDAEcology/edit/master/1.4-additional_basic_material.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
